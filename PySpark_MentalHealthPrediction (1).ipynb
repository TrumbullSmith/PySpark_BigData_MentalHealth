{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robert Smith, Gencer Ates\n",
    "'''\n",
    "We declare that all work submitted for final exam in this report is our own work and does not involve plagiarism\n",
    "or collaboration outside of our own team. We also declare that we have not discussed the problems and\n",
    "solutions with anyone.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSources:\\nhttps://www.kaggle.com/cdc/national-health-and-nutrition-examination-survey\\nhttps://stackoverflow.com/questions/34077353/how-to-change-dataframe-column-names-in-pyspark\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sources:\n",
    "https://www.kaggle.com/cdc/national-health-and-nutrition-examination-survey\n",
    "https://stackoverflow.com/questions/34077353/how-to-change-dataframe-column-names-in-pyspark\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147 oga219\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "port = 4040 + hash(os.getcwd().split(\"/\")[2])%200\n",
    "config = pyspark.SparkConf().set('spark.executor.memory', '512M')\\\n",
    "            .set('spark.cores.max', '4')\\\n",
    "            .set('spark.port.maxRetries','200')\\\n",
    "            .set('spark.ui.port', port)\\\n",
    "            .set('spark.master', 'spark://polyp1:7077')\\\n",
    "            .set('spark.app.name', \"legDay\") \n",
    "print port,     os.getcwd().split(\"/\")[2]\n",
    "#sc = pyspark.SparkContext(appName=\"Project 1\", master='spark://polyp1:7077',conf = config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legDay\n",
      "spark://polyp1:7077\n"
     ]
    }
   ],
   "source": [
    "ss = pyspark.sql.SparkSession.builder.config(conf = config).getOrCreate()\n",
    "\n",
    "print ss.conf.get('spark.app.name')\n",
    "print ss.conf.get('spark.master')\n",
    "\n",
    "#### Input data\n",
    "sc = ss.sparkContext\n",
    "examinationRDD = sc.textFile(\"/scratch/ISE495/2018_project_02/NHANES/examination.csv\")\n",
    "demographicRDD = sc.textFile(\"/scratch/ISE495/2018_project_02/NHANES/demographic.csv\")\n",
    "otherRDD = sc.textFile(\"/scratch/ISE495/2018_project_02/NHANES/other.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1: preparing the data for SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/examination.csv\", header = True ,inferSchema = True) #224 columns\n",
    "df1 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/demographic.csv\", header = True ,inferSchema = True) #47 columns\n",
    "# df2 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/diet.csv\", header = True ,inferSchema = True) #168 columns\n",
    "# df4 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/labs.csv\", header = True ,inferSchema = True) #424 columns\n",
    "# df5 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/medications.csv\", header = True ,inferSchema = True) #13 columns\n",
    "df6 = ss.read.csv(\"/scratch/ISE495/2018_project_02/NHANES/questionnaire.csv\", header = True ,inferSchema = True) #953 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df3.join(df1, [ \"SEQN\" ])\n",
    "'''\n",
    "    #not using medication becaus it has multiples of same\n",
    "''' \n",
    "df = df.dropDuplicates(subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1.1: Understand the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print df.dtypes #matches column names with data types within columns\n",
    "# print df #shows column names with data types within columns\n",
    "# print df.show()\n",
    "# print df.explain(True)  #explains logical & physical plans\n",
    "# print len(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.2: divide df into veteran vs. non-veteran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"kingDF\")\n",
    "\n",
    "veteranDF = ss.\\\n",
    "    sql(\"FROM kingDF WHERE DMQMILIZ=1\")\n",
    "civilianDF = ss.\\\n",
    "    sql(\"FROM kingDF WHERE DMQMILIZ=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteranDF.createOrReplaceTempView(\"veteranDFsql\")\n",
    "veteranDFtest = ss.\\\n",
    "    sql(\"SELECT DMQMILIZ FROM veteranDFsql WHERE DMQMILIZ=2\")\n",
    "\n",
    "#veteranDFtest.show() --> \n",
    "# +--------+\n",
    "# |DMQMILIZ|\n",
    "# +--------+\n",
    "# +--------+\n",
    "# works out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (2016 - 1982) + 18 # 1972 # # print (1973+1991)/2 = 1982 # 2016 --> #52 is the cut-off age for seperation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.3: divide veterans and non-veterans into relevant age groups, and then convert those data frames back into rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "veteranDF.createOrReplaceTempView(\"vetsOlderSql\")\n",
    "vetDFolder = ss.\\\n",
    "    sql(\"FROM vetsOlderSql WHERE RIDAGEYR > 52\") #SELECT RIDAGEYR == age > 50 # print vetDFolder.count() --> 386\n",
    "vetDFyounger = ss.\\\n",
    "    sql(\"FROM vetsOlderSql WHERE RIDAGEYR <= 52\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetDFolder.describe(['RIDAGEYR']).show()\n",
    "# +-------+-----------------+\n",
    "# |summary|         RIDAGEYR|\n",
    "# +-------+-----------------+\n",
    "# |  count|              386|\n",
    "# |   mean|70.20466321243524|\n",
    "# | stddev|8.569779521966169|\n",
    "# |    min|               53|\n",
    "# |    max|               80|\n",
    "# +-------+-----------------+\n",
    "\n",
    "# vetDFyounger.describe(['RIDAGEYR']).show()\n",
    "# +-------+-----------------+\n",
    "# |summary|         RIDAGEYR|\n",
    "# +-------+-----------------+\n",
    "# |  count|              137|\n",
    "# |   mean|40.08759124087591|\n",
    "# | stddev|9.410159132050369|\n",
    "# |    min|               19|\n",
    "# |    max|               52|\n",
    "# +-------+-----------------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are only using the corresponding age ranges of the civilians to compare to veterans\n",
    "civilianDF.createOrReplaceTempView(\"CivisSql\")\n",
    "civiDFolder = ss.\\\n",
    "    sql(\"FROM CivisSql WHERE RIDAGEYR > 52\") #SELECT RIDAGEYR == age > 50 # print vetDFolder.count() --> 386\n",
    "civiDFyounger = ss.\\\n",
    "    sql(\"FROM CivisSql WHERE RIDAGEYR > 19 AND RIDAGEYR < 53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert back to RDD\n",
    "\n",
    "vetRddOlder = vetDFolder.rdd\n",
    "vetRddYounger = vetDFyounger.rdd\n",
    "\n",
    "civiRddOlder = civiDFolder.rdd\n",
    "civiRddYounger = civiDFyounger.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MapPartitionsRDD[74] at javaToPython at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print civiRddOlder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Do Dimensionality Reduction on identified important data, then normalize that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we performed this task by hand-selecting data that seemed most important from the most valuable files\n",
    "\n",
    "keep_list_examination = [\"BPXSY1\",\"BPXDI1\",\"BMXBMI\",\"OHDEXSTS\"]\n",
    "# == [\"bloodPressure_systolic\",\"bloodPressure_dyastolic\",\"weight\",\"height_cm\",\"BMI\",\"oralHealthStatus\"]\n",
    "keep_list_demographics = [\"SEQN\",\"DMDEDUC2\",\"DMDFMSIZ\",\"DMDHHSIZ\",\\\n",
    "                          \"DMDHHSZE\",\"RIAGENDR\", \"DMDMARTL\", \"INDFMPIR\"]\n",
    "# == [\"ID\",\"highestGradeSchool\",\"totalPeopleInFamily\",\"totalPeopleInHouse\"]\\\n",
    "#    [ \"numAdultsinHouse\",\"gender\",\"maritalStatus\",\"ratioIncometoPoverty]\n",
    "\n",
    "# keep_list_examination = [\"BPXSY1 as bloodPressure_systolic\",\"BPXDI1 as bloodPressure_dyastolic\",\"BMXWT as weight\",\"BMXHT as height_cm\",\"BMXBMI as BMI\",\"OHDEXSTS as oralHealthStatus\"]\n",
    "# keep_list_demographics = [\"SEQN as ID\",\"DMDEDUC2 as highestGradeSchool\",\"DMDFMSIZ as totalPeopleInFamily\",\"DMDHHSIZ as totalPeopleInHouse\",\"DMDHHSZA as numChildren1\",\"DMDHHSZB as numChildren2\",\\\n",
    "#                           \"DMDHHSZE as numAdultsinHouse\",\"RIAGENDR as gender\", \"DMDMARTL as maritalStatus\", \"INDFMPIR as ratioIncometoPoverty\"]\n",
    "keep_list_medcolsToAdd = [\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 merging columns together for data normalization\n",
    "\n",
    "# select columns (of kids, and fill null values with 0)\n",
    "\n",
    "colsToAdd = [\"SEQN\",\"DMDHHSZA\",\"DMDHHSZB\"]\n",
    "dfForKids = vetDFolder.select([column for column in df.columns if column in colsToAdd])\\\n",
    ".na.fill(0)\n",
    "\n",
    "dfForKids1 = vetDFyounger.select([column for column in df.columns if column in colsToAdd])\\\n",
    ".na.fill(0)\n",
    "\n",
    "dfForKids2 = civiDFolder.select([column for column in df.columns if column in colsToAdd])\\\n",
    ".na.fill(0)\n",
    "\n",
    "dfForKids3 = civiDFyounger.select([column for column in df.columns if column in colsToAdd])\\\n",
    ".na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine kids columns into one column\n",
    "\n",
    "dfForKids_total = dfForKids.withColumn('totalKids', (dfForKids.DMDHHSZA + dfForKids.DMDHHSZB)).drop('DMDHHSZA',\"DMDHHSZB\")\\\n",
    "# .fillna(_average_,subset=[\"column name\"]) -- for replacing with average instead of null\n",
    "# dfForKids_total.show(4)\n",
    "# +-----+---------+\n",
    "# | SEQN|totalKids|\n",
    "# +-----+---------+\n",
    "# |80900|        0|\n",
    "# |82949|        0|\n",
    "# |83684|        0|\n",
    "# |79201|        1|\n",
    "# +-----+---------+\n",
    "# only showing top 4 rows\n",
    "\n",
    "\n",
    "dfForKids_total1 = dfForKids1.withColumn('totalKids', (dfForKids1.DMDHHSZA + dfForKids1.DMDHHSZB)).drop('DMDHHSZA',\"DMDHHSZB\")\n",
    "# dfForKids_total1.show(4)\n",
    "# +-----+---------+\n",
    "# | SEQN|totalKids|\n",
    "# +-----+---------+\n",
    "# |82359|        0|\n",
    "# |77095|        0|\n",
    "# |77682|        1|\n",
    "# |78963|        0|\n",
    "# +-----+---------+\n",
    "# only showing top 4 rows\n",
    "\n",
    "dfForKids_total2 = dfForKids2.withColumn('totalKids', (dfForKids2.DMDHHSZA + dfForKids2.DMDHHSZB)).drop('DMDHHSZA',\"DMDHHSZB\")\n",
    "# dfForKids_total2.show(4)\n",
    "# +-----+---------+\n",
    "# | SEQN|totalKids|\n",
    "# +-----+---------+\n",
    "# |73723|        0|\n",
    "# |75860|        0|\n",
    "# |76395|        0|\n",
    "# |76932|        0|\n",
    "# +-----+---------+\n",
    "# only showing top 4 rows\n",
    "\n",
    "dfForKids_total3 = dfForKids3.withColumn('totalKids', (dfForKids3.DMDHHSZA + dfForKids3.DMDHHSZB)).drop('DMDHHSZA',\"DMDHHSZB\")\n",
    "# dfForKids_total3.show(4)\n",
    "# +-----+---------+\n",
    "# | SEQN|totalKids|\n",
    "# +-----+---------+\n",
    "# |74498|        2|\n",
    "# |74551|        0|\n",
    "# |75274|        0|\n",
    "# |75328|        0|\n",
    "# +-----+---------+\n",
    "# only showing top 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 131.670391061 67.7877094972 28.888976378\n"
     ]
    }
   ],
   "source": [
    "# 1.2 replacing null values of certain columns with their averages\n",
    "\n",
    "# find averages of specified health-related columns within each of the four datasets\n",
    "\n",
    "fIt = vetDFolder.describe(\"BPXSY1\", \"BPXDI1\", \"BMXBMI\").rdd.map(tuple)\n",
    "def myDude(rdd):\n",
    "    summary = rdd[0]\n",
    "    bloodPressure_systolic = float(rdd[1])\n",
    "    bloodPressure_dyastolic = float(rdd[2])\n",
    "    BMI = float(rdd[3])\n",
    "    return (summary, bloodPressure_systolic, bloodPressure_dyastolic, BMI)\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "avgSys = myDuderdd[1][1]\n",
    "avgDys = myDuderdd[1][2]\n",
    "avgBMI = myDuderdd[1][3]\n",
    "print \"0:\", avgSys, avgDys, avgBMI\n",
    "# 131.670391061 67.7877094972 28.888976378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 119.59375 73.015625 28.6614814815\n"
     ]
    }
   ],
   "source": [
    "fIt = vetDFyounger.describe(\"BPXSY1\", \"BPXDI1\", \"BMXBMI\").rdd.map(tuple)\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "avgSys1 = myDuderdd[1][1]\n",
    "avgDys1 = myDuderdd[1][2]\n",
    "avgBMI1 = myDuderdd[1][3]\n",
    "print \"1:\",avgSys1, avgDys1, avgBMI1\n",
    "# 119.59375 73.015625 28.6614814815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 131.767777778 69.6444444444 29.3429221436\n"
     ]
    }
   ],
   "source": [
    "fIt = civiDFolder.describe(\"BPXSY1\", \"BPXDI1\", \"BMXBMI\").rdd.map(tuple)\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "avgSys2 = myDuderdd[1][1]\n",
    "avgDys2 = myDuderdd[1][2]\n",
    "avgBMI2 = myDuderdd[1][3]\n",
    "print \"2:\",avgSys2, avgDys2, avgBMI2\n",
    "# 131.767777778 69.6444444444 29.3429221436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: 116.768849558 70.2194690265 28.9927296761\n"
     ]
    }
   ],
   "source": [
    "fIt = civiDFyounger.describe(\"BPXSY1\", \"BPXDI1\", \"BMXBMI\").rdd.map(tuple)\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "avgSys3 = myDuderdd[1][1]\n",
    "avgDys3 = myDuderdd[1][2]\n",
    "avgBMI3 = myDuderdd[1][3]\n",
    "print \"3:\",avgSys3, avgDys3, avgBMI3\n",
    "# 116.768849558 70.2194690265 28.9927296761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SEQN', 'DMDEDUC2', 'DMDFMSIZ', 'DMDHHSIZ', 'DMDHHSZE', 'RIAGENDR', 'DMDMARTL', 'INDFMPIR', 'BPXSY1', 'BPXDI1', 'BMXBMI', 'OHDEXSTS']\n"
     ]
    }
   ],
   "source": [
    "# task 1.3 isolate self-identified important variables per each of the 4 datasets\n",
    "\n",
    "#list of things that we need to subset in each of the 4 datasets\n",
    "\n",
    "keep_list = keep_list_demographics + keep_list_examination #+ keep_list_medcolsToAdd\n",
    "print keep_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapping up tasks\n",
    "\n",
    "# 1: reducing entire demographics and examination datasets to a selected columns\n",
    "# 2: merging with the altered kid count list\n",
    "# 3: renaming the variables to be more telling of their importance\n",
    "# 4: we are killing weight and height because they are relative to each other, and replaceable by BMI\n",
    "# 5: replace nulls within certain columns with their averages for each of the 4 datasets (don't need to do this for kids because it's already done previously)\n",
    "\n",
    "vetDFOlder_DimensionReduction = vetDFolder.select([column for column in df.columns if column in keep_list])\\\n",
    ".join(dfForKids_total, [\"SEQN\"])\\\n",
    ".selectExpr(\"SEQN as ID\",\"DMDEDUC2 as highestGradeSchool\",\"DMDFMSIZ as totalPeopleInFamily\",\"DMDHHSIZ as totalPeopleInHouse\",\"totalKids as totalKids_1\",\\\n",
    "           \"BPXSY1 as bloodPressure_systolic\",\"BPXDI1 as bloodPressure_dyastolic\",\"BMXBMI as BMI\",\"OHDEXSTS as oralHealthStatus\")\\\n",
    ".fillna(avgSys,subset=[\"bloodPressure_systolic\"]).fillna(avgDys,subset=[\"bloodPressure_dyastolic\"]).fillna(avgBMI,subset=[\"BMI\"])\n",
    "\n",
    "vetDFYounger_DimensionReduction = vetDFyounger.select([column for column in df.columns if column in keep_list])\\\n",
    ".join(dfForKids_total1, [\"SEQN\"])\\\n",
    ".selectExpr(\"SEQN as ID\",\"DMDEDUC2 as highestGradeSchool\",\"DMDFMSIZ as totalPeopleInFamily\",\"DMDHHSIZ as totalPeopleInHouse\",\"totalKids as totalKids_1\",\\\n",
    "           \"BPXSY1 as bloodPressure_systolic\",\"BPXDI1 as bloodPressure_dyastolic\",\"BMXBMI as BMI\",\"OHDEXSTS as oralHealthStatus\")\\\n",
    ".fillna(avgSys1,subset=[\"bloodPressure_systolic\"]).fillna(avgDys1,subset=[\"bloodPressure_dyastolic\"]).fillna(avgBMI1,subset=[\"BMI\"])\n",
    "\n",
    "\n",
    "\n",
    "civiDFOlder_DimensionReduction = civiDFolder.select([column for column in df.columns if column in keep_list])\\\n",
    ".join(dfForKids_total2, [\"SEQN\"])\\\n",
    ".selectExpr(\"SEQN as ID\",\"DMDEDUC2 as highestGradeSchool\",\"DMDFMSIZ as totalPeopleInFamily\",\"DMDHHSIZ as totalPeopleInHouse\",\"totalKids as totalKids_1\",\\\n",
    "           \"BPXSY1 as bloodPressure_systolic\",\"BPXDI1 as bloodPressure_dyastolic\",\"BMXBMI as BMI\",\"OHDEXSTS as oralHealthStatus\")\\\n",
    ".fillna(avgSys2,subset=[\"bloodPressure_systolic\"]).fillna(avgDys2,subset=[\"bloodPressure_dyastolic\"]).fillna(avgBMI2,subset=[\"BMI\"])\n",
    "\n",
    "civiDFYounger_DimensionReduction = civiDFyounger.select([column for column in df.columns if column in keep_list])\\\n",
    ".join(dfForKids_total3, [\"SEQN\"])\\\n",
    ".selectExpr(\"SEQN as ID\",\"DMDEDUC2 as highestGradeSchool\",\"DMDFMSIZ as totalPeopleInFamily\",\"DMDHHSIZ as totalPeopleInHouse\",\"totalKids as totalKids_1\",\\\n",
    "           \"BPXSY1 as bloodPressure_systolic\",\"BPXDI1 as bloodPressure_dyastolic\",\"BMXBMI as BMI\",\"OHDEXSTS as oralHealthStatus\")\\\n",
    ".fillna(avgSys3,subset=[\"bloodPressure_systolic\"]).fillna(avgDys3,subset=[\"bloodPressure_dyastolic\"]).fillna(avgBMI3,subset=[\"BMI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vetDFOlder_DimensionReduction.show(2)\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |   ID|highestGradeSchool|totalPeopleInFamily|totalPeopleInHouse|totalKids_1|bloodPressure_systolic|bloodPressure_dyastolic| BMI|oralHealthStatus|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |79220|                 3|                  4|                 4|          0|                   126|                     80|31.9|               1|\n",
    "# |82582|                 1|                  2|                 2|          0|                   144|                     78|31.9|               1|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# only showing top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetDFYounger_DimensionReduction.show(3)\n",
    "\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |   ID|highestGradeSchool|totalPeopleInFamily|totalPeopleInHouse|totalKids_1|bloodPressure_systolic|bloodPressure_dyastolic| BMI|oralHealthStatus|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |83291|                 4|                  4|                 4|          2|                   119|                     73|30.1|               1|\n",
    "# |82500|                 5|                  4|                 4|          2|                   130|                     72|35.5|               1|\n",
    "# |80335|                 3|                  1|                 4|          2|                   128|                     70|28.4|               1|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# only showing top 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# civiDFOlder_DimensionReduction.show(2)\n",
    "\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |   ID|highestGradeSchool|totalPeopleInFamily|totalPeopleInHouse|totalKids_1|bloodPressure_systolic|bloodPressure_dyastolic| BMI|oralHealthStatus|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |74058|                 2|                  5|                 5|          0|                   128|                     70|34.2|               1|\n",
    "# |77422|                 5|                  2|                 2|          0|                   168|                     60|21.1|               1|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# only showing top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# civiDFYounger_DimensionReduction.show(2)\n",
    "\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |   ID|highestGradeSchool|totalPeopleInFamily|totalPeopleInHouse|totalKids_1|bloodPressure_systolic|bloodPressure_dyastolic| BMI|oralHealthStatus|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# |74166|                 5|                  5|                 5|          3|                   120|                     76|22.9|               1|\n",
    "# |74251|                 3|                  4|                 4|          1|                   108|                     72|22.9|               1|\n",
    "# +-----+------------------+-------------------+------------------+-----------+----------------------+-----------------------+----+----------------+\n",
    "# only showing top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1: \n",
    "#1 filter df of medications to the important columns\n",
    "#2 & #3 join with 4 datasets & reduce to important cols\n",
    "#4 find average for each mental helath column\n",
    "#5 replace mental health nulls with average\n",
    "#6 add all mental health columns together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 filter df of medications to the important columns\n",
    "\n",
    "medcolsToAdd = [\"SEQN\",\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\"]\n",
    "\n",
    "dfForMeds = df6.select([column for column in df6.columns if column in medcolsToAdd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetDFolder_seqn = vetDFolder.select(\"SEQN\")\n",
    "# vetDFolder_seqn.show(4)\n",
    "vetDFyounger_seqn = vetDFyounger.select(\"SEQN\")\n",
    "civiDFolder_seqn = civiDFolder.select(\"SEQN\")\n",
    "civiDFyounger_seqn = civiDFyounger.select(\"SEQN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfForMeds.show(4)\n",
    "\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# | SEQN|DPQ010|DPQ020|DPQ030|DPQ040|DPQ050|DPQ060|DPQ070|DPQ080|DPQ090|\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# |73557|     1|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |73558|     2|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |73559|     0|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |73560|  null|  null|  null|  null|  null|  null|  null|  null|  null|\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# only showing top 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# joining mental health records with each type of person\n",
    "\n",
    "vetDFolder_wMed = vetDFolder.join(dfForMeds,[\"SEQN\"])\n",
    "# print vetDFolder.show()\n",
    "vetDFyounger_wMed = vetDFyounger.join(dfForMeds,[\"SEQN\"])\n",
    "civiDFolder_wMed = civiDFolder.join(dfForMeds,[\"SEQN\"])\n",
    "civiDFyounger_wMed = civiDFyounger.join(dfForMeds,[\"SEQN\"])\n",
    "# print civiDFyounger_seqn.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78686.253886 0.466850828729 0.32320441989 0.569060773481 0.709944751381 0.279005524862 0.237569060773 0.290055248619 0.182320441989\n"
     ]
    }
   ],
   "source": [
    "# Get average value per group of people for replacing nulls \n",
    "\n",
    "fIt = vetDFolder_wMed.describe(\"SEQN\",\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").rdd.map(tuple)\n",
    "def myDude(rdd):\n",
    "    summary = rdd[0]\n",
    "    o1 = float(rdd[1])\n",
    "    o2 = float(rdd[2])\n",
    "    o3 = float(rdd[3])\n",
    "    o4 = float(rdd[4])\n",
    "    o5 = float(rdd[5])\n",
    "    o6 = float(rdd[6])\n",
    "    o7 = float(rdd[7])\n",
    "    o8 = float(rdd[8])\n",
    "    o9 = float(rdd[9])\n",
    "    return (o1,o2,o3,o4,o5,o6,o7,o8, o9)\n",
    "\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "\n",
    "avgDPQ010 = myDuderdd[1][0]\n",
    "avgDPQ020 = myDuderdd[1][1]\n",
    "avgDPQ030 = myDuderdd[1][2]\n",
    "avgDPQ040 = myDuderdd[1][3]\n",
    "avgDPQ050 = myDuderdd[1][4]\n",
    "avgDPQ060 = myDuderdd[1][5]\n",
    "avgDPQ070 = myDuderdd[1][6]\n",
    "avgDPQ080 = myDuderdd[1][7]\n",
    "avgDPQ090 = myDuderdd[1][8]\n",
    "# print myDuderdd\n",
    "print avgDPQ010, avgDPQ020, avgDPQ030, avgDPQ040, avgDPQ050, avgDPQ060, avgDPQ070, avgDPQ080, avgDPQ090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78594.2992701 0.424242424242 0.409090909091 0.590909090909 0.719696969697 0.439393939394 0.272727272727 0.310606060606 0.219696969697\n"
     ]
    }
   ],
   "source": [
    "fIt = vetDFyounger_wMed.describe(\"SEQN\",\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").rdd.map(tuple)\n",
    "\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "\n",
    "avgDPQ0101 = myDuderdd[1][0]\n",
    "avgDPQ0201 = myDuderdd[1][1]\n",
    "avgDPQ0301 = myDuderdd[1][2]\n",
    "avgDPQ0401 = myDuderdd[1][3]\n",
    "avgDPQ0501 = myDuderdd[1][4]\n",
    "avgDPQ0601 = myDuderdd[1][5]\n",
    "avgDPQ0701 = myDuderdd[1][6]\n",
    "avgDPQ0801 = myDuderdd[1][7]\n",
    "avgDPQ0901 = myDuderdd[1][8]\n",
    "# print myDuderdd\n",
    "print avgDPQ0101, avgDPQ0201, avgDPQ0301, avgDPQ0401, avgDPQ0501, avgDPQ0601, avgDPQ0701, avgDPQ0801, avgDPQ0901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78563.0793257 0.486297689414 0.451612903226 0.696611081226 0.813878429263 0.428187197418 0.320236813778 0.337997847147 0.231969860065\n"
     ]
    }
   ],
   "source": [
    "fIt = civiDFolder_wMed.describe(\"SEQN\",\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").rdd.map(tuple)\n",
    "\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "\n",
    "avgDPQ0102 = myDuderdd[1][0]\n",
    "avgDPQ0202 = myDuderdd[1][1]\n",
    "avgDPQ0302 = myDuderdd[1][2]\n",
    "avgDPQ0402 = myDuderdd[1][3]\n",
    "avgDPQ0502 = myDuderdd[1][4]\n",
    "avgDPQ0602 = myDuderdd[1][5]\n",
    "avgDPQ0702 = myDuderdd[1][6]\n",
    "avgDPQ0802 = myDuderdd[1][7]\n",
    "avgDPQ0902 = myDuderdd[1][8]\n",
    "# print myDuderdd\n",
    "print avgDPQ0102, avgDPQ0202, avgDPQ0302, avgDPQ0402, avgDPQ0502, avgDPQ0602, avgDPQ0702, avgDPQ0802, avgDPQ0902\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78731.6220472 0.367706422018 0.328193832599 0.582599118943 0.758810572687 0.393171806167 0.247797356828 0.260279001468 0.143906020558\n"
     ]
    }
   ],
   "source": [
    "fIt = civiDFyounger_wMed.describe(\"SEQN\",\"DPQ010\",\"DPQ020\",\"DPQ030\"\\\n",
    "                                          ,\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").rdd.map(tuple)\n",
    "myDuderdd= fIt.map(myDude).collect()\n",
    "\n",
    "avgDPQ0103 = myDuderdd[1][0]\n",
    "avgDPQ0203 = myDuderdd[1][1]\n",
    "avgDPQ0303 = myDuderdd[1][2]\n",
    "avgDPQ0403 = myDuderdd[1][3]\n",
    "avgDPQ0503 = myDuderdd[1][4]\n",
    "avgDPQ0603 = myDuderdd[1][5]\n",
    "avgDPQ0703 = myDuderdd[1][6]\n",
    "avgDPQ0803 = myDuderdd[1][7]\n",
    "avgDPQ0903 = myDuderdd[1][8]\n",
    "# print myDuderdd\n",
    "print avgDPQ0103, avgDPQ0203, avgDPQ0303, avgDPQ0403, avgDPQ0503, avgDPQ0603, avgDPQ0703, avgDPQ0803, avgDPQ0903"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the keep list smaller\n",
    "\n",
    "keepList_2 = [\"SEQN\",\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\"]\n",
    "\n",
    "vetDFolder_wMed2 = vetDFolder_wMed.select([column for column in df6.columns if column in keepList_2])\n",
    "vetDFyounger_wMed2 = vetDFyounger_wMed.select([column for column in df6.columns if column in keepList_2])\n",
    "civiDFolder_wMed2 = civiDFolder_wMed.select([column for column in df6.columns if column in keepList_2])\n",
    "civiDFyounger_wMed2 = civiDFyounger_wMed.select([column for column in df6.columns if column in keepList_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print vetDFolder_wMed2.show(2)\n",
    "\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# | SEQN|DPQ010|DPQ020|DPQ030|DPQ040|DPQ050|DPQ060|DPQ070|DPQ080|DPQ090|\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# |80900|     0|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |82949|     0|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# +-----+------+------+------+------+------+------+------+------+------+\n",
    "# only showing top 2 rows\n",
    "\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should narrow the df down to mental health related ones only\n",
    "#it should also replace nulls with their repective averages for each data set\n",
    "\n",
    "vetDFolder_noNull = vetDFolder_wMed.fillna(avgDPQ020,subset=[\"DPQ020\"]).fillna(avgDPQ030,subset=[\"DPQ030\"]).fillna(avgDPQ040,subset=[\"DPQ040\"]).fillna(avgDPQ050,subset=[\"DPQ050\"]).fillna(avgDPQ060,subset=[\"DPQ060\"]).fillna(avgDPQ070,subset=[\"DPQ070\"]).fillna(avgDPQ080,subset=[\"DPQ080\"]).fillna(avgDPQ090,subset=[\"DPQ0290\"])\n",
    "vetDFyounger_noNull = vetDFyounger_wMed.fillna(avgDPQ0201,subset=[\"DPQ020\"]).fillna(avgDPQ0301,subset=[\"DPQ030\"]).fillna(avgDPQ0401,subset=[\"DPQ040\"]).fillna(avgDPQ0501,subset=[\"DPQ050\"]).fillna(avgDPQ0601,subset=[\"DPQ060\"]).fillna(avgDPQ0701,subset=[\"DPQ070\"]).fillna(avgDPQ0801,subset=[\"DPQ080\"]).fillna(avgDPQ0901,subset=[\"DPQ0290\"])\n",
    "civiDFolder_noNull = civiDFolder_wMed.fillna(avgDPQ0202,subset=[\"DPQ020\"]).fillna(avgDPQ0302,subset=[\"DPQ030\"]).fillna(avgDPQ0402,subset=[\"DPQ040\"]).fillna(avgDPQ0502,subset=[\"DPQ050\"]).fillna(avgDPQ0602,subset=[\"DPQ060\"]).fillna(avgDPQ0702,subset=[\"DPQ070\"]).fillna(avgDPQ0802,subset=[\"DPQ080\"]).fillna(avgDPQ0902,subset=[\"DPQ0290\"])\n",
    "civiDFyounger_noNull = civiDFyounger_wMed.fillna(avgDPQ0203,subset=[\"DPQ020\"]).fillna(avgDPQ0303,subset=[\"DPQ030\"]).fillna(avgDPQ0403,subset=[\"DPQ040\"]).fillna(avgDPQ0503,subset=[\"DPQ050\"]).fillna(avgDPQ0603,subset=[\"DPQ060\"]).fillna(avgDPQ0703,subset=[\"DPQ070\"]).fillna(avgDPQ0803,subset=[\"DPQ080\"]).fillna(avgDPQ0903,subset=[\"DPQ0290\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print vetDFolder_noNull.show(2)\n",
    "\n",
    "# +-----+--------+--------+--------+------+------+------+------+-------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+--------+-----+-----+--------+--------+-------+-------+-----+-----+------+-------+------+------+-------+-------+-------+-------+--------+--------+-------+-------+-------+-------+--------+--------+--------+------+------+------+------+------+------+------+------+------+-------+-------+--------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+--------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------+------+-------+-------+-------+-------+-------+-------+------+------+------+------+------+------+--------+--------+-------+-------+--------+--------+--------+--------+-------+-------+-------+--------+-------+--------+--------+--------+--------+-------+--------+--------+--------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------------+------------+-------+--------+--------+--------+--------+------+------+------+------+------+------+------+------+------+\n",
    "# | SEQN|PEASCST1|PEASCTM1|PEASCCT1|BPXCHR|BPAARM|BPACSZ|BPXPLS|BPXPULS|BPXPTY|BPXML1|BPXSY1|BPXDI1|BPAEN1|BPXSY2|BPXDI2|BPAEN2|BPXSY3|BPXDI3|BPAEN3|BPXSY4|BPXDI4|BPAEN4|BMDSTATS|BMXWT|BMIWT|BMXRECUM|BMIRECUM|BMXHEAD|BMIHEAD|BMXHT|BMIHT|BMXBMI|BMDBMIC|BMXLEG|BMILEG|BMXARML|BMIARML|BMXARMC|BMIARMC|BMXWAIST|BMIWAIST|BMXSAD1|BMXSAD2|BMXSAD3|BMXSAD4|BMDAVSAD|BMDSADCM|MGDEXSTS|MGD050|MGD060|MGQ070|MGQ080|MGQ090|MGQ100|MGQ110|MGQ120|MGD130|MGQ90DG|MGDSEAT|MGAPHAND|MGATHAND|MGXH1T1|MGXH1T1E|MGXH2T1|MGXH2T1E|MGXH1T2|MGXH1T2E|MGXH2T2|MGXH2T2E|MGXH1T3|MGXH1T3E|MGXH2T3|MGXH2T3E|MGDCGSZ|OHDEXSTS|OHDDESTS|OHXIMP|OHX01TC|OHX02TC|OHX03TC|OHX04TC|OHX05TC|OHX06TC|OHX07TC|OHX08TC|OHX09TC|OHX10TC|OHX11TC|OHX12TC|OHX13TC|OHX14TC|OHX15TC|OHX16TC|OHX17TC|OHX18TC|OHX19TC|OHX20TC|OHX21TC|OHX22TC|OHX23TC|OHX24TC|OHX25TC|OHX26TC|OHX27TC|OHX28TC|OHX29TC|OHX30TC|OHX31TC|OHX32TC|OHX02CTC|OHX03CTC|OHX04CTC|OHX05CTC|OHX06CTC|OHX07CTC|OHX08CTC|OHX09CTC|OHX10CTC|OHX11CTC|OHX12CTC|OHX13CTC|OHX14CTC|OHX15CTC|OHX18CTC|OHX19CTC|OHX20CTC|OHX21CTC|OHX22CTC|OHX23CTC|OHX24CTC|OHX25CTC|OHX26CTC|OHX27CTC|OHX28CTC|OHX29CTC|OHX30CTC|OHX31CTC|OHX02CSC|OHX03CSC|OHX04CSC|OHX05CSC|OHX06CSC|OHX07CSC|OHX08CSC|OHX09CSC|OHX10CSC|OHX11CSC|OHX12CSC|OHX13CSC|OHX14CSC|OHX15CSC|OHX18CSC|OHX19CSC|OHX20CSC|OHX21CSC|OHX22CSC|OHX23CSC|OHX24CSC|OHX25CSC|OHX26CSC|OHX27CSC|OHX28CSC|OHX29CSC|OHX30CSC|OHX31CSC|OHX02SE|OHX03SE|OHX04SE|OHX05SE|OHX07SE|OHX10SE|OHX12SE|OHX13SE|OHX14SE|OHX15SE|OHX18SE|OHX19SE|OHX20SE|OHX21SE|OHX28SE|OHX29SE|OHX30SE|OHX31SE|CSXEXSTS|CSXEXCMT|CSQ245|CSQ241|CSQ260A|CSQ260D|CSQ260G|CSQ260I|CSQ260N|CSQ260M|CSQ270|CSQ450|CSQ460|CSQ470|CSQ480|CSQ490|CSXQUIPG|CSXQUIPT|CSXNAPG|CSXNAPT|CSXQUISG|CSXQUIST|CSXSLTSG|CSXSLTST|CSXNASG|CSXNAST|CSXTSEQ|CSXCHOOD|CSXSBOD|CSXSMKOD|CSXLEAOD|CSXSOAOD|CSXGRAOD|CSXONOD|CSXNGSOD|CSXSLTRT|CSXSLTRG|CSXNART|CSXNARG|CSAEFFRT|SDDSRVYR|RIDSTATR|RIAGENDR|RIDAGEYR|RIDAGEMN|RIDRETH1|RIDRETH3|RIDEXMON|RIDEXAGM|DMQMILIZ|DMQADFC|DMDBORN4|DMDCITZN|DMDYRSUS|DMDEDUC3|DMDEDUC2|DMDMARTL|RIDEXPRG|SIALANG|SIAPROXY|SIAINTRP|FIALANG|FIAPROXY|FIAINTRP|MIALANG|MIAPROXY|MIAINTRP|AIALANGA|DMDHHSIZ|DMDFMSIZ|DMDHHSZA|DMDHHSZB|DMDHHSZE|DMDHRGND|DMDHRAGE|DMDHRBR4|DMDHREDU|DMDHRMAR|DMDHSEDU|    WTINT2YR|    WTMEC2YR|SDMVPSU|SDMVSTRA|INDHHIN2|INDFMIN2|INDFMPIR|DPQ010|DPQ020|DPQ030|DPQ040|DPQ050|DPQ060|DPQ070|DPQ080|DPQ090|\n",
    "# +-----+--------+--------+--------+------+------+------+------+-------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+--------+-----+-----+--------+--------+-------+-------+-----+-----+------+-------+------+------+-------+-------+-------+-------+--------+--------+-------+-------+-------+-------+--------+--------+--------+------+------+------+------+------+------+------+------+------+-------+-------+--------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+--------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------+------+-------+-------+-------+-------+-------+-------+------+------+------+------+------+------+--------+--------+-------+-------+--------+--------+--------+--------+-------+-------+-------+--------+-------+--------+--------+--------+--------+-------+--------+--------+--------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------------+------------+-------+--------+--------+--------+--------+------+------+------+------+------+------+------+------+------+\n",
    "# |80900|       1|     974|    null|  null|     1|     5|    76|      1|     1|   140|   112|    70|     2|   116|    72|     2|   116|    76|     2|  null|  null|  null|       1| 84.8| null|    null|    null|   null|   null|162.3| null|  32.2|   null|  37.8|  null|   38.2|   null|   36.1|   null|   106.8|    null|   26.1|   26.3|   null|   null|    26.2|    null|       1|     2|  null|     2|  null|  null|     2|  null|  null|     1|      1|      1|       2|       1|   33.3|       1|   34.4|       1|   34.0|       1|   34.6|       1|   34.4|       1|   34.7|       1|   69.1|       1|       1|     2|      4|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      4|      4|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      2|      4|       Z|       Z|       Z|       Z|       S|       S|       S|       S|       S|       S|       Z|       Z|       Z|       Z|       Z|       Z|       Z|       Z|       S|       S|       S|       S|       S|       S|       S|       Z|       Z|       Z|      68|   56789|   56789|   56789|    null|    null|    null|    null|    null|    null|   56789|   56789|   56789|      68|   56789|   56789|   56789|      69|    null|    null|    null|    null|    null|    null|    null|   56789|   56789|   56789|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|       1|    null|     2|  null|   null|   null|   null|   null|      1|   null|  null|    15|    36|    20|     8|    53|       7|       2|     32|      2|      56|       2|      43|       1|     17|      1|      B|       2|      1|       3|       3|       1|       2|      3|       2|    null|    null|     28|      1|       1|       8|       2|       1|      66|    null|       1|       1|       2|    null|       1|      1|       1|       1|    null|    null|       4|       3|    null|      1|       2|       2|   null|    null|    null|      1|       2|       2|       1|       3|       3|       0|       0|       3|       1|      60|       1|       3|       2|    null|13833.936085|14908.252501|      2|     107|    null|    null|    null|     0|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |82949|       1|    1225|    null|  null|     2|     4|    74|      1|     1|   150|   128|    64|     2|   132|    68|     2|   126|    62|     2|  null|  null|  null|       1|116.1| null|    null|    null|   null|   null|186.0| null|  33.6|   null|  43.5|  null|   40.2|   null|   40.6|   null|   116.5|    null|   29.6|   29.6|   null|   null|    29.6|    null|       1|     2|  null|     2|  null|  null|     2|  null|  null|     1|      1|      1|       1|       2|   45.1|       1|   52.5|       1|   47.8|       1|   51.6|       1|   48.1|       1|   52.2|       1|  100.6|       1|       1|     2|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|      4|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|       P|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|    null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|   null|       1|    null|     2|  null|   null|   null|   null|   null|   null|      1|  null|     8|    22|    25|     5|    31|      18|       2|     19|      1|      20|       2|      34|       1|     17|      1|      B|       2|      1|       3|       2|       1|       3|      3|       4|      34|       1|   null|   null|       1|       8|       2|       1|      67|    null|       3|       3|       1|    null|       1|      1|       1|       1|    null|    null|       3|       1|    null|      1|       2|       2|      1|       2|       2|      1|       2|       2|       1|       2|       2|       0|       0|       2|       2|      67|       1|       3|       1|       3|96081.098846|96459.977987|      1|     116|       7|       7|    2.26|     0|     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# +-----+--------+--------+--------+------+------+------+------+-------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+--------+-----+-----+--------+--------+-------+-------+-----+-----+------+-------+------+------+-------+-------+-------+-------+--------+--------+-------+-------+-------+-------+--------+--------+--------+------+------+------+------+------+------+------+------+------+-------+-------+--------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+-------+--------+--------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+------+------+-------+-------+-------+-------+-------+-------+------+------+------+------+------+------+--------+--------+-------+-------+--------+--------+--------+--------+-------+-------+-------+--------+-------+--------+--------+--------+--------+-------+--------+--------+--------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+-------+--------+--------+-------+--------+--------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------------+------------+-------+--------+--------+--------+--------+------+------+------+------+------+------+------+------+------+\n",
    "# only showing top 2 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 reduce to important cols\n",
    "# this should add all of the columns into a column and then delete the old columns, leaving one summed collumn\n",
    "\n",
    "dfMedsOldVets = vetDFolder_noNull\\\n",
    ".withColumn('totalMentalHealthProblems', (vetDFolder_noNull.DPQ020 + \\\n",
    "                                                       vetDFolder_noNull.DPQ030 + vetDFolder_noNull.DPQ040 + vetDFolder_noNull.DPQ050 + \\\n",
    "                                                       vetDFolder_noNull.DPQ060 + vetDFolder_noNull.DPQ070 + vetDFolder_noNull.DPQ080 + \\\n",
    "                                                       vetDFolder_noNull.DPQ090))\\\n",
    ".drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "\n",
    "dfMedsYungVets = vetDFyounger_noNull\\\n",
    ".withColumn('totalMentalHealthProblems', (vetDFyounger_noNull.DPQ020 + \\\n",
    "                                                       vetDFyounger_noNull.DPQ030 + vetDFyounger_noNull.DPQ040 + vetDFyounger_noNull.DPQ050 + \\\n",
    "                                                       vetDFyounger_noNull.DPQ060 + vetDFyounger_noNull.DPQ070 + vetDFyounger_noNull.DPQ080 + \\\n",
    "                                                       vetDFyounger_noNull.DPQ090))\\\n",
    ".drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "\n",
    "dfMedsOldCivs = civiDFolder_noNull\\\n",
    ".withColumn('totalMentalHealthProblems', (civiDFolder_noNull.DPQ020 + \\\n",
    "                                                       civiDFolder_noNull.DPQ030 + civiDFolder_noNull.DPQ040 + civiDFolder_noNull.DPQ050 + \\\n",
    "                                                       civiDFolder_noNull.DPQ060 + civiDFolder_noNull.DPQ070 + civiDFolder_noNull.DPQ080 + \\\n",
    "                                                       civiDFolder_noNull.DPQ090))\\\n",
    ".drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "\n",
    "dfMedsYungCivs = civiDFyounger_noNull\\\n",
    ".withColumn('totalMentalHealthProblems', (civiDFyounger_noNull.DPQ020 + \\\n",
    "                                                       civiDFyounger_noNull.DPQ030 + civiDFyounger_noNull.DPQ040 + civiDFyounger_noNull.DPQ050 + \\\n",
    "                                                       civiDFyounger_noNull.DPQ060 + civiDFyounger_noNull.DPQ070 + civiDFyounger_noNull.DPQ080 + \\\n",
    "                                                       civiDFyounger_noNull.DPQ090))\\\n",
    ".drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMedsOldVets_clean_total = dfMedsOldVets.select('SEQN','totalMentalHealthProblems')\n",
    "dfMedsOldVets_clean_individual = vetDFolder_noNull.select('SEQN',\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").fillna(0)\n",
    "dfMedsYungVets_clean_total = dfMedsYungVets.select('SEQN','totalMentalHealthProblems')\n",
    "vetDFyounger_clean_individual = vetDFyounger_noNull.select('SEQN',\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").fillna(0)\n",
    "\n",
    "dfMedsOldCivs_clean_total = dfMedsOldCivs.select('SEQN','totalMentalHealthProblems')\n",
    "civiDFolder_clean_individual = civiDFolder_noNull.select('SEQN',\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").fillna(0)\n",
    "dfMedsYungCivs_clean_total = dfMedsYungCivs.select('SEQN','totalMentalHealthProblems')\n",
    "civiDFyounger_clean_individual = civiDFyounger_noNull.select('SEQN',\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMedsOldVets_clean.show(4)\n",
    "\n",
    "# +-----+-------------------------+\n",
    "# | SEQN|totalMentalHealthProblems|\n",
    "# +-----+-------------------------+\n",
    "# |80900|                        0|\n",
    "# |82949|                        0|\n",
    "# |83684|                        0|\n",
    "# |79201|                        9|\n",
    "# +-----+-------------------------+\n",
    "# only showing top 4 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print dfMedsOldVets_clean_individual.show(3)\n",
    "\n",
    "# +------+------+------+------+------+------+------+------+\n",
    "# |DPQ020|DPQ030|DPQ040|DPQ050|DPQ060|DPQ070|DPQ080|DPQ090|\n",
    "# +------+------+------+------+------+------+------+------+\n",
    "# |     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# |     0|     0|     0|     0|     0|     0|     0|     0|\n",
    "# +------+------+------+------+------+------+------+------+\n",
    "# only showing top 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMedsOldVets_clean_individual.count()\n",
    "# ---> 386"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \"DPQ010\",\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "dfsmal = dfMedsOldVets_clean_individual\n",
    "dfMedsOldVets_clean_individual_sum = dfsmal.select([f.sum(dfsmal.DPQ020).alias(\"depres\") , f.sum(dfsmal.DPQ030).alias(\"sleepProb\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ040).alias(\"feelTired\") , f.sum(dfsmal.DPQ050).alias(\"eatDisordr\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ060).alias(\"selfDep\") , f.sum(dfsmal.DPQ070).alias(\"troubConcentrat\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ080).alias(\"behavExtremes_speed\") , f.sum(dfsmal.DPQ090).alias(\"suicidal\") ])\n",
    "dfsmal = vetDFyounger_clean_individual\n",
    "vetDFyounger_clean_individual_sum = dfsmal.select([f.sum(dfsmal.DPQ020).alias(\"depres\") , f.sum(dfsmal.DPQ030).alias(\"sleepProb\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ040).alias(\"feelTired\") , f.sum(dfsmal.DPQ050).alias(\"eatDisordr\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ060).alias(\"selfDep\") , f.sum(dfsmal.DPQ070).alias(\"troubConcentrat\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ080).alias(\"behavExtremes_speed\") , f.sum(dfsmal.DPQ090).alias(\"suicidal\") ])\n",
    "dfsmal = civiDFolder_clean_individual\n",
    "civiDFolder_clean_individual_sum = dfsmal.select([f.sum(dfsmal.DPQ020).alias(\"depres\") , f.sum(dfsmal.DPQ030).alias(\"sleepProb\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ040).alias(\"feelTired\") , f.sum(dfsmal.DPQ050).alias(\"eatDisordr\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ060).alias(\"selfDep\") , f.sum(dfsmal.DPQ070).alias(\"troubConcentrat\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ080).alias(\"behavExtremes_speed\") , f.sum(dfsmal.DPQ090).alias(\"suicidal\") ])\n",
    "dfsmal = civiDFyounger_clean_individual\n",
    "civiDFyounger_clean_individual_sum = dfsmal.select([f.sum(dfsmal.DPQ020).alias(\"depres\") , f.sum(dfsmal.DPQ030).alias(\"sleepProb\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ040).alias(\"feelTired\") , f.sum(dfsmal.DPQ050).alias(\"eatDisordr\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ060).alias(\"selfDep\") , f.sum(dfsmal.DPQ070).alias(\"troubConcentrat\") , \\\n",
    "                                                    f.sum(dfsmal.DPQ080).alias(\"behavExtremes_speed\") , f.sum(dfsmal.DPQ090).alias(\"suicidal\") ])\n",
    "\n",
    "# print \"Old Vets:\"\n",
    "# dfMedsOldVets_clean_individual_sum.show()\n",
    "# Old Vets:\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |depres|sleepProb|feelTired|eatDisordr|selfDep|troubConcentrat|behavExtremes_speed|suicidal|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |   117|      206|      257|       101|     86|            105|                 66|      27|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "\n",
    "# print \"Young Vets:\"\n",
    "# vetDFyounger_clean_individual_sum.show()\n",
    "# Young Vets:\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |depres|sleepProb|feelTired|eatDisordr|selfDep|troubConcentrat|behavExtremes_speed|suicidal|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |    54|       78|       95|        58|     36|             41|                 29|       3|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "\n",
    "# print \"Old Civis:\"\n",
    "# civiDFolder_clean_individual_sum.show()\n",
    "# Old Civis:\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |depres|sleepProb|feelTired|eatDisordr|selfDep|troubConcentrat|behavExtremes_speed|suicidal|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |   840|     1295|     1513|       796|    595|            628|                431|     125|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "\n",
    "# print \"Young Civis:\"\n",
    "# civiDFyounger_clean_individual_sum.show()\n",
    "# Young Civis:\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |depres|sleepProb|feelTired|eatDisordr|selfDep|troubConcentrat|behavExtremes_speed|suicidal|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+\n",
    "# |   894|     1587|     2067|      1071|    675|            709|                392|     132|\n",
    "# +------+---------+---------+----------+-------+---------------+-------------------+--------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch\n",
    "\n",
    "# SELECT AVG(column_name)\n",
    "# FROM table_name;\n",
    "\n",
    "# print dfMedsOldVets_clean_individual.count()\n",
    "\n",
    "# print vetDFyounger_clean_individual.count()\n",
    "\n",
    "# print civiDFolder_clean_individual.count()\n",
    "\n",
    "# print civiDFyounger_clean_individual.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfMedsOldVets_clean_individual.describe(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").show()\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
    "# |summary|             DPQ020|            DPQ030|            DPQ040|            DPQ050|             DPQ060|             DPQ070|             DPQ080|             DPQ090|\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
    "# |  count|                386|               386|               386|               386|                386|                386|                386|                362|\n",
    "# |   mean|0.30310880829015546| 0.533678756476684|0.6658031088082902|0.2616580310880829|0.22279792746113988|0.27202072538860106|0.17098445595854922|0.07458563535911603|\n",
    "# | stddev| 0.7306575395341216|0.9508194362920108|0.9478459530659812|0.7738796491218413| 0.7294178042018186| 0.7935418283465443| 0.5782082173533148| 0.3902772217549807|\n",
    "# |    min|                  0|                 0|                 0|                 0|                  0|                  0|                  0|                  0|\n",
    "# |    max|                  3|                 3|                 3|                 9|                  9|                  9|                  3|                  3|\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+-------------------+\n",
    "\n",
    "# vetDFyounger_clean_individual.describe(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").show()\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+--------------------+\n",
    "# |summary|             DPQ020|            DPQ030|            DPQ040|            DPQ050|             DPQ060|             DPQ070|            DPQ080|              DPQ090|\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+--------------------+\n",
    "# |  count|                137|               137|               137|               137|                137|                137|               137|                 132|\n",
    "# |   mean|0.39416058394160586|0.5693430656934306|0.6934306569343066|0.4233576642335766|0.26277372262773724|0.29927007299270075|0.2116788321167883|0.022727272727272728|\n",
    "# | stddev| 0.7892444659067064|0.9377352288261911|1.0258572010735307|0.8199948685028309| 0.6215501611566313| 0.7511262475506717|0.6798643564355812| 0.19402955196768357|\n",
    "# |    min|                  0|                 0|                 0|                 0|                  0|                  0|                 0|                   0|\n",
    "# |    max|                  3|                 3|                 3|                 3|                  3|                  3|                 3|                   2|\n",
    "# +-------+-------------------+------------------+------------------+------------------+-------------------+-------------------+------------------+--------------------+\n",
    "\n",
    "# civiDFolder_clean_individual.describe(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").show()\n",
    "# +-------+------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+\n",
    "# |summary|            DPQ020|            DPQ030|            DPQ040|             DPQ050|            DPQ060|            DPQ070|             DPQ080|             DPQ090|\n",
    "# +-------+------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+\n",
    "# |  count|              2017|              2017|              2017|               2017|              2017|              2017|               2017|               1857|\n",
    "# |   mean|0.4164600892414477|0.6420426375805652|0.7501239464551314|0.39464551313832424|0.2949925632126921|0.3113534952900347|0.21368368864650472|0.06731287022078622|\n",
    "# | stddev|0.8706449229529122|1.0161285618136693|0.9945442615595778| 0.8054446948852524|0.7866316782752238| 0.770381143093377| 0.6853419702362752|   0.42331428572023|\n",
    "# |    min|                 0|                 0|                 0|                  0|                 0|                 0|                  0|                  0|\n",
    "# |    max|                 9|                 7|                 7|                  3|                 9|                 9|                  9|                  9|\n",
    "# +-------+------------------+------------------+------------------+-------------------+------------------+------------------+-------------------+-------------------+\n",
    "\n",
    "# civiDFyounger_clean_individual.describe(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\").show()\n",
    "# +-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+--------------------+\n",
    "# |summary|            DPQ020|            DPQ030|            DPQ040|            DPQ050|             DPQ060|             DPQ070|             DPQ080|              DPQ090|\n",
    "# +-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+--------------------+\n",
    "# |  count|              3048|              3048|              3048|              3048|               3048|               3048|               3048|                2724|\n",
    "# |   mean|0.2933070866141732|0.5206692913385826|0.6781496062992126|0.3513779527559055|0.22145669291338582|0.23261154855643046|0.12860892388451445|0.048458149779735685|\n",
    "# | stddev|0.6660661112169177|0.8916889780389664|0.8847734239581017|0.7579951733586822| 0.5990685068548548|  0.632787139712549| 0.4680768430785099|  0.3305941880325175|\n",
    "# |    min|                 0|                 0|                 0|                 0|                  0|                  0|                  0|                   0|\n",
    "# |    max|                 7|                 3|                 3|                 9|                  3|                  3|                  3|                   9|\n",
    "# +-------+------------------+------------------+------------------+------------------+-------------------+-------------------+-------------------+--------------------+\n",
    "\n",
    "# |    max|                 9|                 7|                 7|                  9|                  9                   9                   9                    9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old vet mean\n",
      "[0.3031, 0.5336, 0.6658, 0.2616, 0.2227, 0.272, 0.17098, 0.07458]\n",
      "young vet mean\n",
      "[0.3941, 0.56934, 0.6934, 0.4233, 0.2627, 0.2992, 0.21167, 0.0227]\n",
      "old civ mean\n",
      "(0.4164, 0.642, 0.7501, 0.394645, 0.29499, 0.3113, 0.21368, 0.06731)\n",
      "young civ mean\n",
      "[0.2933, 0.52066, 0.6781, 0.35137, 0.2214, 0.2326, 0.1286, 0.04845]\n"
     ]
    }
   ],
   "source": [
    "print \"old vet mean\"\n",
    "oldVetMean = [0.3031,0.5336, 0.6658, 0.2616, 0.2227, 0.2720, 0.17098, 0.07458]\n",
    "print oldVetMean\n",
    "print \"young vet mean\"\n",
    "youngVetMean = [0.3941,0.56934,0.6934,0.4233,0.2627,0.2992,0.21167,0.0227]\n",
    "print youngVetMean\n",
    "print \"old civ mean\"\n",
    "oldCivMean = (0.4164,0.6420,0.7501,0.394645,0.29499,0.3113,0.21368,0.06731)\n",
    "print oldCivMean\n",
    "print \"young civ mean\"\n",
    "youngCivMean = [0.29330,0.52066,0.6781,0.35137,0.2214,0.2326,0.12860,0.04845]\n",
    "print youngCivMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "# 2.2 reduce to important cols\n",
    "# this should add all of the columns into a column and then delete the old columns, leaving one summed collumn\n",
    "\n",
    "vetDFolder_clean_normalized = dfMedsOldVets_clean_individual\\\n",
    ".withColumn('DPQ020N', (dfMedsOldVets_clean_individual.DPQ020 / 3.)) \\\n",
    ".withColumn('DPQ030N', (dfMedsOldVets_clean_individual.DPQ030 / 3.)) \\\n",
    ".withColumn('DPQ040N', (dfMedsOldVets_clean_individual.DPQ040 / 3.)) \\\n",
    ".withColumn('DPQ050N', (dfMedsOldVets_clean_individual.DPQ050 / 9.)) \\\n",
    ".withColumn('DPQ060N', (dfMedsOldVets_clean_individual.DPQ060 / 9.)) \\\n",
    ".withColumn('DPQ070N', (dfMedsOldVets_clean_individual.DPQ070 / 9.)) \\\n",
    ".withColumn('DPQ080N', (dfMedsOldVets_clean_individual.DPQ080 / 3.)) \\\n",
    ".withColumn('DPQ090N', (dfMedsOldVets_clean_individual.DPQ090 / 3.)).drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "# vetDFolder_clean_normalized.show(2)\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# | SEQN|DPQ020N|DPQ030N|DPQ040N|DPQ050N|DPQ060N|DPQ070N|DPQ080N|DPQ090N|\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# |82949|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|\n",
    "# |80900|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# only showing top 2 rows\n",
    "\n",
    "\n",
    "vetDFyounger_clean_normalized = vetDFyounger_clean_individual\\\n",
    ".withColumn('DPQ020N', (vetDFyounger_clean_individual.DPQ020 / 3.)) \\\n",
    ".withColumn('DPQ030N', (vetDFyounger_clean_individual.DPQ030 / 3.)) \\\n",
    ".withColumn('DPQ040N', (vetDFyounger_clean_individual.DPQ040 / 3.)) \\\n",
    ".withColumn('DPQ050N', (vetDFyounger_clean_individual.DPQ050 / 3.)) \\\n",
    ".withColumn('DPQ060N', (vetDFyounger_clean_individual.DPQ060 / 3.)) \\\n",
    ".withColumn('DPQ070N', (vetDFyounger_clean_individual.DPQ070 / 3.)) \\\n",
    ".withColumn('DPQ080N', (vetDFyounger_clean_individual.DPQ080 / 3.)) \\\n",
    ".withColumn('DPQ090N', (vetDFyounger_clean_individual.DPQ090 / 2.)).drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "# vetDFyounger_clean_normalized.show(2)\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# | SEQN|DPQ020N|DPQ030N|DPQ040N|DPQ050N|DPQ060N|DPQ070N|DPQ080N|DPQ090N|\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# |82359|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|\n",
    "# |77095|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|\n",
    "# +-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
    "# only showing top 2 rows\n",
    "\n",
    "civiDFolder_clean_normalized = civiDFolder_clean_individual\\\n",
    ".withColumn('DPQ020N', (civiDFolder_clean_individual.DPQ020 / 9.)) \\\n",
    ".withColumn('DPQ030N', (civiDFolder_clean_individual.DPQ030 / 7.)) \\\n",
    ".withColumn('DPQ040N', (civiDFolder_clean_individual.DPQ040 / 7.)) \\\n",
    ".withColumn('DPQ050N', (civiDFolder_clean_individual.DPQ050 / 3.)) \\\n",
    ".withColumn('DPQ060N', (civiDFolder_clean_individual.DPQ060 / 9.)) \\\n",
    ".withColumn('DPQ070N', (civiDFolder_clean_individual.DPQ070 / 9.)) \\\n",
    ".withColumn('DPQ080N', (civiDFolder_clean_individual.DPQ080 / 9.)) \\\n",
    ".withColumn('DPQ090N', (civiDFolder_clean_individual.DPQ090 / 9.)).drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "# civiDFolder_clean_normalized.show(2)\n",
    "# +-----+-------+-------------------+-------------------+-------+------------------+-------+------------------+-------+\n",
    "# | SEQN|DPQ020N|            DPQ030N|            DPQ040N|DPQ050N|           DPQ060N|DPQ070N|           DPQ080N|DPQ090N|\n",
    "# +-----+-------+-------------------+-------------------+-------+------------------+-------+------------------+-------+\n",
    "# |73723|    0.0|0.14285714285714285|0.14285714285714285|    0.0|               0.0|    0.0|0.1111111111111111|    0.0|\n",
    "# |75860|    0.0|                0.0|0.14285714285714285|    0.0|0.1111111111111111|    0.0|               0.0|    0.0|\n",
    "# +-----+-------+-------------------+-------------------+-------+------------------+-------+------------------+-------+\n",
    "# only showing top 2 rows\n",
    "\n",
    "civiDFyounger_clean_normalized = civiDFyounger_clean_individual\\\n",
    ".withColumn('DPQ020N', (civiDFyounger_clean_individual.DPQ020 / 7.)) \\\n",
    ".withColumn('DPQ030N', (civiDFyounger_clean_individual.DPQ030 / 3.)) \\\n",
    ".withColumn('DPQ040N', (civiDFyounger_clean_individual.DPQ040 / 3.)) \\\n",
    ".withColumn('DPQ050N', (civiDFyounger_clean_individual.DPQ050 / 9.)) \\\n",
    ".withColumn('DPQ060N', (civiDFyounger_clean_individual.DPQ060 / 3.)) \\\n",
    ".withColumn('DPQ070N', (civiDFyounger_clean_individual.DPQ070 / 3.)) \\\n",
    ".withColumn('DPQ080N', (civiDFyounger_clean_individual.DPQ080 / 3.)) \\\n",
    ".withColumn('DPQ090N', (civiDFyounger_clean_individual.DPQ090 / 9.)).drop(\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\")\n",
    "# civiDFyounger_clean_normalized.show(2)\n",
    "# +-----+-------+-------+------------------+------------------+-------+-------+-------+-------+\n",
    "# | SEQN|DPQ020N|DPQ030N|           DPQ040N|           DPQ050N|DPQ060N|DPQ070N|DPQ080N|DPQ090N|\n",
    "# +-----+-------+-------+------------------+------------------+-------+-------+-------+-------+\n",
    "# |74498|    0.0|    0.0|0.3333333333333333|0.1111111111111111|    0.0|    0.0|    0.0|    0.0|\n",
    "# |74551|    0.0|    0.0|0.3333333333333333|               0.0|    0.0|    0.0|    0.0|    0.0|\n",
    "# +-----+-------+-------+------------------+------------------+-------+-------+-------+-------+\n",
    "# only showing top 2 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch\n",
    "\n",
    "# from pyspark.ml.linalg import Vectors\n",
    "# test = civiDFyounger_clean_normalized\\\n",
    "# .withColumn('test', ([civiDFyounger_clean_normalized.DPQ020N,civiDFyounger_clean_normalized.DPQ030N,civiDFyounger_clean_normalized.DPQ040N,civiDFyounger_clean_normalized.DPQ050N,civiDFyounger_clean_normalized.DPQ060N,civiDFyounger_clean_normalized.DPQ070N,civiDFyounger_clean_normalized.DPQ080N,civiDFyounger_clean_normalized.DPQ090N]))\n",
    "# test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA as PCA1\n",
    "pca = PCA1(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.fillna(0)\n",
    "from pyspark.ml.feature import PCA as PCA2\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(73557, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])), (73558, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))]\n"
     ]
    }
   ],
   "source": [
    "filterningCols_med = [\"SEQN\",\"DPQ020\",\"DPQ030\",\"DPQ040\",\"DPQ050\",\"DPQ060\",\"DPQ070\",\"DPQ080\",\"DPQ090\"]\n",
    "df_med_master = df6.select([column for column in df6.columns if column in filterningCols_med]).na.fill(0).rdd.map(list)\\\n",
    ".map(lambda x: (x[0], Vectors.dense(x[1:]))).cache()\n",
    "print df_med_master.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|            features|\n",
      "+-----+--------------------+\n",
      "|73557|[0.0,0.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      " alive\n",
      "+-----+-------------------------------------------------------------+\n",
      "|id   |pcaFeatures                                                  |\n",
      "+-----+-------------------------------------------------------------+\n",
      "|73557|[0.0,0.0,0.0]                                                |\n",
      "|73558|[0.0,0.0,0.0]                                                |\n",
      "|73559|[0.0,0.0,0.0]                                                |\n",
      "|73560|[0.0,0.0,0.0]                                                |\n",
      "|73561|[-3.046715548517044,0.11402268151574835,-2.4147302639021935] |\n",
      "|73562|[-6.299060794667952,0.29375429310989465,0.15586500184431606] |\n",
      "|73563|[0.0,0.0,0.0]                                                |\n",
      "|73564|[-0.8920063503859061,0.16925455109708393,-0.6671492016237033]|\n",
      "|73565|[0.0,0.0,0.0]                                                |\n",
      "|73566|[-0.49778294833778247,-0.6344753572995515,0.5716019293133305]|\n",
      "|73567|[-0.8920063503859061,0.16925455109708393,-0.6671492016237033]|\n",
      "|73568|[0.0,0.0,0.0]                                                |\n",
      "|73569|[0.0,0.0,0.0]                                                |\n",
      "|73570|[0.0,0.0,0.0]                                                |\n",
      "|73571|[-2.7419505358628213,-1.577099927423864,0.970940607338623]   |\n",
      "|73572|[0.0,0.0,0.0]                                                |\n",
      "|73573|[0.0,0.0,0.0]                                                |\n",
      "|73574|[-0.356595340463568,0.15707159337770704,-0.07671597897766536]|\n",
      "|73575|[0.0,0.0,0.0]                                                |\n",
      "|73576|[0.0,0.0,0.0]                                                |\n",
      "+-----+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import pyspark.ml.feature\n",
    "from pyspark.ml.feature import PCA as PCA2\n",
    "from pyspark.ml.linalg import Vectors\n",
    "# from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "# data = [(Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
    "#         (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),),\n",
    "#        (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]\n",
    "# print data[0:2]\n",
    "data = df_med_master\n",
    "# print data[0:2]\n",
    "dr_df = ss.createDataFrame(data, [\"id\",\"features\"])\n",
    "# print 'alive'\n",
    "dr_df.show(1)\n",
    "pca = PCA2(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "\n",
    "\n",
    "#---> troublesome code for PCA\n",
    "model = pca.fit(dr_df)\n",
    "print ' alive'\n",
    "result = model.transform(dr_df).select('id',\"pcaFeatures\")\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pairing dimensionality to potential three different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the format for the regressions need to be (feature, [reduced dimensionality])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label:\n",
    "# ID\n",
    "#features:\n",
    "#highestGradeSchool| *\n",
    "#totalPeopleInHouse| *\n",
    "#totalKids_1| \n",
    "# bloodPressure_systolic|\n",
    "# bloodPressure_dyastolic| \n",
    "# BMI/ *\n",
    "\n",
    "# vetDFOlder_DimensionReduction.show()\n",
    "# vetDFYounger_DimensionReduction.show()\n",
    "# civiDFOlder_DimensionReduction.show()\n",
    "# civiDFYounger_DimensionReduction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 1 for testing == [\"highestGradeSchool\"]\n",
    "#scale = 1--5, 1 being kindergarden, 5 being college\n",
    "#goal is to predict if the person will complete college or not given their mental health status \n",
    "# --> >4 == 1 & <4 == 0 (with 1 being yes)\n",
    "featureToGet = [\"ID\",\"highestGradeSchool\"]\n",
    "\n",
    "def normGrade(rdd):\n",
    "    pId = rdd[0]\n",
    "    grade = rdd[1]\n",
    "    retGrade = 0\n",
    "    if grade > 4:\n",
    "        retGrade = 1\n",
    "    else:\n",
    "        retGrade = 0\n",
    "    return [pId, retGrade]\n",
    "\n",
    "\n",
    "#1\n",
    "vetDFOlder_DimensionReduction_gS = vetDFOlder_DimensionReduction.select([column for column in vetDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normGrade)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFOlder_DimensionReduction_gS.take(4) # --> [[79220, 3], [82582, 1], [83250, 4], [78700, 5]] --> [[79220, 0], [82582, 0], [83250, 0], [78700, 1]]\n",
    "vetDFOlder_DimensionReduction_gS_df = ss.createDataFrame(vetDFOlder_DimensionReduction_gS, [\"id\",\"normGrade\"])\n",
    "# vetDFOlder_DimensionReduction_gS_df.show(4)\n",
    "# +-----+---------+\n",
    "# |   id|normGrade|\n",
    "# +-----+---------+\n",
    "# |79220|        0|\n",
    "# |82582|        0|\n",
    "# |83250|        0|\n",
    "# |78700|        1|\n",
    "# +-----+---------+\n",
    "# only showing top 4 rows\n",
    "\n",
    "\n",
    "#2\n",
    "vetDFYounger_DimensionReduction_gS = vetDFYounger_DimensionReduction.select([column for column in vetDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normGrade)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFYounger_DimensionReduction_gS.take(2) --> [[83291, 4], [82500, 5]]\n",
    "vetDFYounger_DimensionReduction_gS_df = ss.createDataFrame(vetDFYounger_DimensionReduction_gS, [\"id\",\"normGrade\"])\n",
    "# vetDFYounger_DimensionReduction_gS_df.show(4)\n",
    "\n",
    "#3\n",
    "civiDFOlder_DimensionReduction_gS = civiDFOlder_DimensionReduction.select([column for column in civiDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normGrade)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFOlder_DimensionReduction_gS.take(2)\n",
    "civiDFOlder_DimensionReduction_gS_df = ss.createDataFrame(civiDFOlder_DimensionReduction_gS, [\"id\",\"normGrade\"])\n",
    "# civiDFOlder_DimensionReduction_gS_df.show(4)\n",
    "\n",
    "#4 \n",
    "civiDFYounger_DimensionReduction_gS = civiDFYounger_DimensionReduction.select([column for column in civiDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normGrade)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFYounger_DimensionReduction_gS.take(2)\n",
    "civiDFYounger_DimensionReduction_gS_df = ss.createDataFrame(civiDFYounger_DimensionReduction_gS, [\"id\",\"normGrade\"])\n",
    "# civiDFYounger_DimensionReduction_gS_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 2 for testing == [\"BMIIIII\"]\n",
    "# 0 - 18.5 = underweight, 18.5 - 25 = normal, 25 - 30 = overweight, 30 + = obese \n",
    "# if it's normal == 1, otherwise = 0, == BMI problem\n",
    "\n",
    "featureToGet = [\"ID\",\"BMI\"]\n",
    "\n",
    "def normBMI(rdd):\n",
    "    pId = rdd[0]\n",
    "    bmi = rdd[1]\n",
    "    retBmi = 0\n",
    "    if (bmi > 18.5) and (bmi < 25.1):\n",
    "        retBmi = 1\n",
    "    else:\n",
    "        retBmi = 0\n",
    "    return [pId, retBmi]\n",
    "\n",
    "\n",
    "#1\n",
    "vetDFOlder_DimensionReduction_BMI = vetDFOlder_DimensionReduction.select([column for column in vetDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normBMI)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFOlder_DimensionReduction_gS.take(4) # --> [[79220, 3], [82582, 1], [83250, 4], [78700, 5]] --> [[79220, 0], [82582, 0], [83250, 0], [78700, 1]]\n",
    "vetDFOlder_DimensionReduction_BMI_df = ss.createDataFrame(vetDFOlder_DimensionReduction_BMI, [\"id\",\"normBMI\"])\n",
    "# vetDFOlder_DimensionReduction_BMI_df.show(4)\n",
    "# +-----+-------+\n",
    "# |   id|normBMI|\n",
    "# +-----+-------+\n",
    "# |79220|      0|\n",
    "# |82582|      0|\n",
    "# |83250|      0|\n",
    "# |78700|      1|\n",
    "# +-----+-------+\n",
    "# # only showing top 4 rows\n",
    "\n",
    "\n",
    "#2\n",
    "vetDFYounger_DimensionReduction_BMI = vetDFYounger_DimensionReduction.select([column for column in vetDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normBMI)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFYounger_DimensionReduction_gS.take(2) --> [[83291, 4], [82500, 5]]\n",
    "vetDFYounger_DimensionReduction_BMI_df = ss.createDataFrame(vetDFYounger_DimensionReduction_BMI, [\"id\",\"normBMI\"])\n",
    "# vetDFYounger_DimensionReduction_BMI_df.show(4)\n",
    "\n",
    "#3\n",
    "civiDFOlder_DimensionReduction_BMI = civiDFOlder_DimensionReduction.select([column for column in civiDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normBMI)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFOlder_DimensionReduction_gS.take(2)\n",
    "civiDFOlder_DimensionReduction_BMI_df = ss.createDataFrame(civiDFOlder_DimensionReduction_BMI, [\"id\",\"normBMI\"])\n",
    "# civiDFOlder_DimensionReduction_BMI_df.show(4)\n",
    "\n",
    "#4 \n",
    "civiDFYounger_DimensionReduction_BMI = civiDFYounger_DimensionReduction.select([column for column in civiDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normBMI)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFYounger_DimensionReduction_gS.take(2)\n",
    "civiDFYounger_DimensionReduction_BMI_df = ss.createDataFrame(civiDFYounger_DimensionReduction_BMI, [\"id\",\"normBMI\"])\n",
    "# civiDFYounger_DimensionReduction_BMI_df.show(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature 3 for testing == [\"totalPeopleInHouse\"]\n",
    "\n",
    "featureToGet = [\"ID\",\"totalPeopleInHouse\"]\n",
    "\n",
    "def normTotPeeps(rdd):\n",
    "    pId = rdd[0]\n",
    "    peeps = rdd[1]\n",
    "    retPeeps = 0\n",
    "    if peeps > 1:\n",
    "        retPeeps = 1\n",
    "    else:\n",
    "        retBmi = 0\n",
    "    return [pId, retPeeps]\n",
    "\n",
    "\n",
    "#1\n",
    "vetDFOlder_DimensionReduction_peeps = vetDFOlder_DimensionReduction.select([column for column in vetDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normTotPeeps)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFOlder_DimensionReduction_gS.take(4) # --> [[79220, 3], [82582, 1], [83250, 4], [78700, 5]] --> [[79220, 0], [82582, 0], [83250, 0], [78700, 1]]\n",
    "vetDFOlder_DimensionReduction_peeps_df = ss.createDataFrame(vetDFOlder_DimensionReduction_peeps, [\"id\",\"normTotPeeps\"])\n",
    "# vetDFOlder_DimensionReduction_peeps_df.show(4)\n",
    "# +-----+-------+\n",
    "# |   id|normBMI|\n",
    "# +-----+-------+\n",
    "# |79220|      0|\n",
    "# |82582|      0|\n",
    "# |83250|      0|\n",
    "# |78700|      1|\n",
    "# +-----+-------+\n",
    "# # only showing top 4 rows\n",
    "\n",
    "\n",
    "#2\n",
    "vetDFYounger_DimensionReduction_peeps = vetDFYounger_DimensionReduction.select([column for column in vetDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normTotPeeps)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print vetDFYounger_DimensionReduction_gS.take(2) --> [[83291, 4], [82500, 5]]\n",
    "vetDFYounger_DimensionReduction_peeps_df = ss.createDataFrame(vetDFYounger_DimensionReduction_peeps, [\"id\",\"normTotPeeps\"])\n",
    "# vetDFYounger_DimensionReduction_peeps_df.show(4)\n",
    "\n",
    "#3\n",
    "civiDFOlder_DimensionReduction_peeps = civiDFOlder_DimensionReduction.select([column for column in civiDFOlder_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normTotPeeps)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFOlder_DimensionReduction_gS.take(2)\n",
    "civiDFOlder_DimensionReduction_peeps_df = ss.createDataFrame(civiDFOlder_DimensionReduction_peeps, [\"id\",\"normTotPeeps\"])\n",
    "# civiDFOlder_DimensionReduction_peeps_df.show(4)\n",
    "\n",
    "#4 \n",
    "civiDFYounger_DimensionReduction_peeps = civiDFYounger_DimensionReduction.select([column for column in civiDFYounger_DimensionReduction.columns if column in featureToGet]).na.fill(0).rdd.map(list).map(normTotPeeps)#.map(lambda x: (x[0], [x[1:]])).cache()\n",
    "# print civiDFYounger_DimensionReduction_gS.take(2)\n",
    "civiDFYounger_DimensionReduction_peeps_df = ss.createDataFrame(civiDFYounger_DimensionReduction_peeps, [\"id\",\"normTotPeeps\"])\n",
    "# civiDFYounger_DimensionReduction_peeps_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Level\n",
      "+---------+--------------------+\n",
      "|normGrade|         pcaFeatures|\n",
      "+---------+--------------------+\n",
      "|        0|       [0.0,0.0,0.0]|\n",
      "|        0|[-2.0804890734159...|\n",
      "+---------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "BMI\n",
      "+-------+--------------------+\n",
      "|normBMI|         pcaFeatures|\n",
      "+-------+--------------------+\n",
      "|      0|       [0.0,0.0,0.0]|\n",
      "|      0|[-2.0804890734159...|\n",
      "+-------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Total Household\n",
      "+------------+--------------------+\n",
      "|normTotPeeps|         pcaFeatures|\n",
      "+------------+--------------------+\n",
      "|           1|       [0.0,0.0,0.0]|\n",
      "|           1|[-2.0804890734159...|\n",
      "+------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join err thing with result\n",
    "# df = df3.join(df1, [ \"SEQN\" ])\n",
    "\n",
    "#Educ Level\n",
    "print 'Education Level'\n",
    "vetDFOlder_Analyse_gS_df = vetDFOlder_DimensionReduction_gS_df.join(result, [ \"id\" ]).select('normGrade', 'pcaFeatures')\n",
    "vetDFOlder_Analyse_gS_df.show(2)\n",
    "\n",
    "vetDFYounger_Analyse_gS_df = vetDFYounger_DimensionReduction_gS_df.join(result, [ \"id\" ]).select('normGrade', 'pcaFeatures')\n",
    "# vetDFYounger_Analyse_gS_df.show(2)\n",
    "\n",
    "civiDFOlder_Analyse_gS_df = civiDFOlder_DimensionReduction_gS_df.join(result, [ \"id\" ]).select('normGrade', 'pcaFeatures')\n",
    "# civiDFOlder_Analyse_gS_df.show(2)\n",
    "\n",
    "civiDFYounger_Analyse_gS_df = civiDFYounger_DimensionReduction_gS_df.join(result, [ \"id\" ]).select('normGrade', 'pcaFeatures')\n",
    "# civiDFYounger_Analyse_gS_df.show(2)\n",
    "\n",
    "#BMI\n",
    "print 'BMI'\n",
    "vetDFOlder_Analyse_BMI_df = vetDFOlder_DimensionReduction_BMI_df.join(result, [ \"id\" ]).select('normBMI', 'pcaFeatures')\n",
    "vetDFOlder_Analyse_BMI_df.show(2)\n",
    "\n",
    "vetDFYounger_Analyse_BMI_df = vetDFYounger_DimensionReduction_BMI_df.join(result, [ \"id\" ]).select('normBMI', 'pcaFeatures')\n",
    "# vetDFYounger_Analyse_BMI_df.show(2)\n",
    "\n",
    "civiDFOlder_Analyse_BMI_df = civiDFOlder_DimensionReduction_BMI_df.join(result, [ \"id\" ]).select('normBMI', 'pcaFeatures')\n",
    "# civiDFOlder_Analyse_BMI_df.show(2)\n",
    "\n",
    "civiDFYounger_Analyse_BMI_df = civiDFYounger_DimensionReduction_BMI_df.join(result, [ \"id\" ]).select('normBMI', 'pcaFeatures')\n",
    "# civiDFYounger_Analyse_BMI_df.show(2)\n",
    "\n",
    "#Total Household\n",
    "print 'Total Household'\n",
    "vetDFOlder_Analyse_peeps_df = vetDFOlder_DimensionReduction_peeps_df.join(result, [ \"id\" ]).select('normTotPeeps', 'pcaFeatures')\n",
    "vetDFOlder_Analyse_peeps_df.show(2)\n",
    "\n",
    "vetDFYounger_Analyse_peeps_df = vetDFYounger_DimensionReduction_peeps_df.join(result, [ \"id\" ]).select('normTotPeeps', 'pcaFeatures')\n",
    "# vetDFYounger_Analyse_peeps_df.show(2)\n",
    "\n",
    "civiDFOlder_Analyse_peeps_df = civiDFOlder_DimensionReduction_peeps_df.join(result, [ \"id\" ]).select('normTotPeeps', 'pcaFeatures')\n",
    "# civiDFOlder_Analyse_peeps_df.show(2)\n",
    "\n",
    "civiDFYounger_Analyse_peeps_df = civiDFYounger_DimensionReduction_peeps_df.join(result, [ \"id\" ]).select('normTotPeeps', 'pcaFeatures')\n",
    "# civiDFYounger_Analyse_peeps_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split the data for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education Level\n",
      "[LabeledPoint(0.0, [-2.0804890734159986,-1.7953973643135597,-0.3742292667188327]), LabeledPoint(0.0, [-0.49778294833778247,-0.6344753572995515,0.5716019293133305])]\n",
      "[LabeledPoint(0.0, [0.0,0.0,0.0]), LabeledPoint(0.0, [-4.057379184873387,0.2310854775494008,-0.1769977049225227])]\n",
      "BMI\n",
      "[LabeledPoint(0.0, [-2.0804890734159986,-1.7953973643135597,-0.3742292667188327]), LabeledPoint(0.0, [-0.49778294833778247,-0.6344753572995515,0.5716019293133305])]\n",
      "[LabeledPoint(0.0, [0.0,0.0,0.0]), LabeledPoint(0.0, [-4.057379184873387,0.2310854775494008,-0.1769977049225227])]\n",
      "Total Household\n",
      "[LabeledPoint(1.0, [-2.0804890734159986,-1.7953973643135597,-0.3742292667188327]), LabeledPoint(0.0, [-0.49778294833778247,-0.6344753572995515,0.5716019293133305])]\n",
      "[LabeledPoint(1.0, [0.0,0.0,0.0]), LabeledPoint(1.0, [-4.057379184873387,0.2310854775494008,-0.1769977049225227])]\n"
     ]
    }
   ],
   "source": [
    "def makingLabledPoint(cleanLine): #this is only used for training\n",
    "    l = cleanLine\n",
    "    ID = l[0]  #this is the feature that we are testing for!!\n",
    "    features = l[1]\n",
    "    negOrPosPoint = LabeledPoint(ID,features)\n",
    "    return negOrPosPoint\n",
    "\n",
    "\n",
    "# join err thing with result\n",
    "# df = df3.join(df1, [ \"SEQN\" ])\n",
    "\n",
    "#Educ Level\n",
    "print 'Education Level'\n",
    "vetDFOlder_Analyse_gS_df_lp_tr   ,   vetDFOlder_Analyse_gS_df_lp_te        = vetDFOlder_Analyse_gS_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "print vetDFOlder_Analyse_gS_df_lp_tr.take(2)\n",
    "print vetDFOlder_Analyse_gS_df_lp_te.take(2)\n",
    "vetDFYounger_Analyse_gS_df_lp_tr,vetDFYounger_Analyse_gS_df_lp_te    = vetDFYounger_Analyse_gS_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFOlder_Analyse_gS_df_lp_tr,civiDFOlder_Analyse_gS_df_lp_te      = civiDFOlder_Analyse_gS_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFYounger_Analyse_gS_df_lp_tr,civiDFYounger_Analyse_gS_df_lp_te  = civiDFYounger_Analyse_gS_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "\n",
    "# #BMI\n",
    "print 'BMI'\n",
    "vetDFOlder_Analyse_BMI_df_lp_tr,vetDFOlder_Analyse_BMI_df_lp_te       = vetDFOlder_Analyse_BMI_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "print vetDFOlder_Analyse_BMI_df_lp_tr.take(2)\n",
    "print vetDFOlder_Analyse_BMI_df_lp_te.take(2)\n",
    "vetDFYounger_Analyse_BMI_df_lp_tr,vetDFYounger_Analyse_BMI_df_lp_te   = vetDFYounger_Analyse_BMI_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFOlder_Analyse_BMI_df_lp_tr,civiDFOlder_Analyse_BMI_df_lp_te     = civiDFOlder_Analyse_BMI_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFYounger_Analyse_BMI_df_lp_tr,civiDFYounger_Analyse_BMI_df_lp_te = civiDFYounger_Analyse_BMI_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "\n",
    "# #Total Household\n",
    "print 'Total Household'\n",
    "vetDFOlder_Analyse_peeps_df_lp_tr,vetDFOlder_Analyse_peeps_df_lp_te   = vetDFOlder_Analyse_peeps_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "print vetDFOlder_Analyse_peeps_df_lp_tr.take(2)\n",
    "print vetDFOlder_Analyse_peeps_df_lp_te.take(2)\n",
    "vetDFYounger_Analyse_peeps_df_lp_tr,vetDFYounger_Analyse_peeps_df_lp_te = vetDFYounger_Analyse_peeps_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFOlder_Analyse_peeps_df_lp_tr,civiDFOlder_Analyse_peeps_df_lp_te  = civiDFOlder_Analyse_peeps_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "civiDFYounger_Analyse_peeps_df_lp_tr,civiDFYounger_Analyse_peeps_df_lp_te = civiDFYounger_Analyse_peeps_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingLabledPoint).randomSplit(weights=[0.7,0.3], seed=1)\n",
    "\n",
    "\n",
    "# t1 = t_all.map(makingLabledPoint)\n",
    "# print t1.take(1)\n",
    "# trainForTesting_labeled = trainForTesting.map(makingLabledPoint)\n",
    "# print trainForTesting_labeled.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression models\n",
    "#1 logistic regression\n",
    "#2 random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######\n",
    "# this is using the same data inputs as the last task - splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "# http://spark.apache.org/docs/2.0.0/api/python/pyspark.mllib.html\n",
    "\n",
    "from math import exp\n",
    "import warnings\n",
    "import numpy\n",
    "from numpy import array\n",
    "from pyspark import RDD, since\n",
    "from pyspark.streaming import DStream\n",
    "from pyspark.mllib.common import callMLlibFunc, _py2java, _java2py\n",
    "from pyspark.mllib.linalg import DenseVector, SparseVector, _convert_to_vector\n",
    "from pyspark.mllib.regression import (\n",
    "    LabeledPoint, LinearModel, _regression_train_wrapper,\n",
    "    StreamingLinearAlgorithm)\n",
    "from pyspark.mllib.util import Saveable, Loader, inherit_doc\n",
    "\n",
    "import sys\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetDFOlder_Analyse_gS_df_lp_tr   ,   vetDFOlder_Analyse_gS_df_lp_te   \n",
    "# vetDFYounger_Analyse_gS_df_lp_tr,vetDFYounger_Analyse_gS_df_lp_te\n",
    "# civiDFOlder_Analyse_gS_df_lp_tr,civiDFOlder_Analyse_gS_df_lp_te\n",
    "# civiDFYounger_Analyse_gS_df_lp_tr,civiDFYounger_Analyse_gS_df_lp_te \n",
    "# vetDFOlder_Analyse_BMI_df_lp_tr,vetDFOlder_Analyse_BMI_df_lp_te\n",
    "# vetDFYounger_Analyse_BMI_df_lp_tr,vetDFYounger_Analyse_BMI_df_lp_te\n",
    "# civiDFOlder_Analyse_BMI_df_lp_tr,civiDFOlder_Analyse_BMI_df_lp_te\n",
    "# civiDFYounger_Analyse_BMI_df_lp_tr,civiDFYounger_Analyse_BMI_df_lp_te\n",
    "# vetDFOlder_Analyse_peeps_df_lp_tr,vetDFOlder_Analyse_peeps_df_lp_te\n",
    "# vetDFYounger_Analyse_peeps_df_lp_tr,vetDFYounger_Analyse_peeps_df_lp_te\n",
    "# civiDFOlder_Analyse_peeps_df_lp_tr,civiDFOlder_Analyse_peeps_df_lp_te\n",
    "# civiDFYounger_Analyse_peeps_df_lp_tr,civiDFYounger_Analyse_peeps_df_lp_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Models##\n",
    "#Education\n",
    "vetDFOlder_model_gS = LogisticRegressionWithLBFGS.train(vetDFOlder_Analyse_gS_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "vetDFYounger_model_gS = LogisticRegressionWithLBFGS.train(vetDFYounger_Analyse_gS_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFOlder_model_gS = LogisticRegressionWithLBFGS.train(civiDFOlder_Analyse_gS_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFYounger_model_gS = LogisticRegressionWithLBFGS.train(civiDFYounger_Analyse_gS_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "#BMI\n",
    "vetDFOlder_model_BMI = LogisticRegressionWithLBFGS.train(vetDFOlder_Analyse_BMI_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "vetDFYounger_model_BMI = LogisticRegressionWithLBFGS.train(vetDFYounger_Analyse_BMI_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFOlder_model_BMI = LogisticRegressionWithLBFGS.train(civiDFOlder_Analyse_BMI_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFYounger_model_BMI = LogisticRegressionWithLBFGS.train(civiDFYounger_Analyse_BMI_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "#Household\n",
    "vetDFOlder_model_peeps = LogisticRegressionWithLBFGS.train(vetDFOlder_Analyse_peeps_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "vetDFYounger_model_peeps = LogisticRegressionWithLBFGS.train(vetDFYounger_Analyse_peeps_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFOlder_model_peeps = LogisticRegressionWithLBFGS.train(civiDFOlder_Analyse_peeps_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n",
    "\n",
    "civiDFYounger_model_peeps = LogisticRegressionWithLBFGS.train(civiDFYounger_Analyse_peeps_df_lp_tr,\\\n",
    "                                                                    iterations=10, regParam=0.000000001,\\\n",
    "                                                                    regType='l2', intercept=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Models##\n",
    "#Education\n",
    "vetDFOlder_model_gS\n",
    "vetDFYounger_model_gS\n",
    "civiDFOlder_model_gS \n",
    "civiDFYounger_model_gS\n",
    "#BMI\n",
    "vetDFOlder_model_BMI \n",
    "vetDFYounger_model_BMI\n",
    "civiDFOlder_model_BMI \n",
    "civiDFYounger_model_BMI\n",
    "#Household\n",
    "vetDFOlder_model_peeps\n",
    "vetDFYounger_model_peeps\n",
    "civiDFOlder_model_peeps \n",
    "civiDFYounger_model_peeps\n",
    "\n",
    "##testing data##\n",
    "vetDFOlder_Analyse_gS_df_lp_te\n",
    "vetDFYounger_Analyse_gS_df_lp_te\n",
    "civiDFOlder_Analyse_gS_df_lp_te\n",
    "civiDFYounger_Analyse_gS_df_lp_te\n",
    "\n",
    "vetDFOlder_Analyse_BMI_df_lp_te\n",
    "vetDFYounger_Analyse_BMI_df_lp_te\n",
    "civiDFOlder_Analyse_BMI_df_lp_te\n",
    "civiDFYounger_Analyse_BMI_df_lp_te\n",
    "\n",
    "vetDFOlder_Analyse_peeps_df_lp_te\n",
    "vetDFYounger_Analyse_peeps_df_lp_te\n",
    "civiDFOlder_Analyse_peeps_df_lp_te\n",
    "civiDFYounger_Analyse_peeps_df_lp_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print vetDFOlder_model_gS.predict([-0.49778294833778247,-0.6344753572995515,0.5716019293133305])\n",
    "print vetDFOlder_model_gS.predict([-4.057379184873387,0.2310854775494008,-0.1769977049225227])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Vet Educ Training Error = 0.29197080292\n",
      "Young Vet Educ Training Error = 0.309278350515\n",
      "Old Civ Educ Training Error = 0.227687983134\n",
      "Young Civ Educ Training Error = 0.260344026034\n",
      "Old Vet BMI Training Error = 0.248175182482\n",
      "Young Vet BMI Training Error = 0.237113402062\n",
      "Old Civ BMI Training Error = 0.26212227688\n",
      "Young Civ BMI Training Error = 0.314737331474\n",
      "Old Vet Household Training Error = 0.222627737226\n",
      "Young Vet Household Training Error = 0.113402061856\n",
      "Old Civ Household Training Error = 0.231201686578\n",
      "Young Civ Household Training Error = 0.068340306834\n"
     ]
    }
   ],
   "source": [
    "labelsAndPreds = vetDFOlder_Analyse_gS_df_lp_tr.map(lambda p: (p.label, vetDFOlder_model_gS.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFOlder_Analyse_gS_df_lp_tr.count())\n",
    "print(\"Old Vet Educ Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = vetDFYounger_Analyse_gS_df_lp_tr.map(lambda p: (p.label, vetDFYounger_model_gS.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFYounger_Analyse_gS_df_lp_tr.count())\n",
    "print(\"Young Vet Educ Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFOlder_Analyse_gS_df_lp_tr.map(lambda p: (p.label, civiDFOlder_model_gS.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFOlder_Analyse_gS_df_lp_tr.count())\n",
    "print(\"Old Civ Educ Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFYounger_Analyse_gS_df_lp_tr.map(lambda p: (p.label, civiDFYounger_model_gS.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFYounger_Analyse_gS_df_lp_tr.count())\n",
    "print(\"Young Civ Educ Training Error = \" + str(trainErr))\n",
    "\n",
    "\n",
    "labelsAndPreds = vetDFOlder_Analyse_BMI_df_lp_tr.map(lambda p: (p.label, vetDFOlder_model_BMI.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFOlder_Analyse_BMI_df_lp_tr.count())\n",
    "print(\"Old Vet BMI Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = vetDFYounger_Analyse_BMI_df_lp_tr.map(lambda p: (p.label, vetDFYounger_model_BMI.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFYounger_Analyse_BMI_df_lp_tr.count())\n",
    "print(\"Young Vet BMI Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFOlder_Analyse_BMI_df_lp_tr.map(lambda p: (p.label, civiDFOlder_model_BMI.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFOlder_Analyse_BMI_df_lp_tr.count())\n",
    "print(\"Old Civ BMI Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFYounger_Analyse_BMI_df_lp_tr.map(lambda p: (p.label, civiDFYounger_model_BMI.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFYounger_Analyse_BMI_df_lp_tr.count())\n",
    "print(\"Young Civ BMI Training Error = \" + str(trainErr))\n",
    "\n",
    "\n",
    "labelsAndPreds = vetDFOlder_Analyse_peeps_df_lp_tr.map(lambda p: (p.label, vetDFOlder_model_peeps.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFOlder_Analyse_peeps_df_lp_tr.count())\n",
    "print(\"Old Vet Household Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = vetDFYounger_Analyse_peeps_df_lp_tr.map(lambda p: (p.label, vetDFYounger_model_peeps.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(vetDFYounger_Analyse_peeps_df_lp_tr.count())\n",
    "print(\"Young Vet Household Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFOlder_Analyse_peeps_df_lp_tr.map(lambda p: (p.label, civiDFOlder_model_peeps.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFOlder_Analyse_peeps_df_lp_tr.count())\n",
    "print(\"Old Civ Household Training Error = \" + str(trainErr))\n",
    "\n",
    "labelsAndPreds = civiDFYounger_Analyse_peeps_df_lp_tr.map(lambda p: (p.label, civiDFYounger_model_peeps.predict(p.features)))\n",
    "trainErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(civiDFYounger_Analyse_peeps_df_lp_tr.count())\n",
    "print(\"Young Civ Household Training Error = \" + str(trainErr))\n",
    "\n",
    "#with testing data\n",
    "# Old Vet Educ Training Error = 0.241071428571\n",
    "# Young Vet Educ Training Error = 0.325\n",
    "# Old Civ Educ Training Error = 0.220538720539 *\n",
    "# Young Civ Educ Training Error = 0.266443701226\n",
    "\n",
    "# Old Vet BMI Training Error = 0.223214285714 *\n",
    "# Young Vet BMI Training Error = 0.175 *\n",
    "# Old Civ BMI Training Error = 0.23063973064\n",
    "# Young Civ BMI Training Error = 0.324414715719\n",
    "\n",
    "# Old Vet Household Training Error = 0.241071428571\n",
    "# Young Vet Household Training Error = 0.225 \n",
    "# Old Civ Household Training Error = 0.232323232323\n",
    "# Young Civ Household Training Error = 0.0602006688963*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Old Vet BMI Training Error = 0.223214285714 *\n",
    "# Young Vet BMI Training Error = 0.175 *\n",
    "# Old Civ Educ Training Error = 0.220538720539 *\n",
    "# Young Civ Household Training Error = 0.0602006688963*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#with training data\n",
    "# Old Vet Educ Training Error = 0.29197080292\n",
    "# Young Vet Educ Training Error = 0.309278350515\n",
    "# Old Civ Educ Training Error = 0.227687983134\n",
    "# Young Civ Educ Training Error = 0.260344026034\n",
    "\n",
    "# Old Vet BMI Training Error = 0.248175182482\n",
    "# Young Vet BMI Training Error = 0.237113402062\n",
    "# Old Civ BMI Training Error = 0.26212227688\n",
    "# Young Civ BMI Training Error = 0.314737331474\n",
    "\n",
    "# Old Vet Household Training Error = 0.222627737226\n",
    "# Young Vet Household Training Error = 0.113402061856\n",
    "# Old Civ Household Training Error = 0.231201686578\n",
    "# Young Civ Household Training Error = 0.068340306834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Civ Educ Training Error = 0.220538720539\n",
    "# Young Vet BMI Training Error = 0.175\n",
    "# Young Civ Household Training Error = 0.0602006688963\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# select most telling feature for each data group\n",
    "#create testing vectors of mental health - reduced using PCA - of size 20\n",
    "#get average feature prediction for each data group run on testing vectors\n",
    "#compare averages between similar data sets\n",
    "#what vector combinations give what kinds of results? - within each dataset\n",
    "#comparing vector types and results across every dataset - are there any vector types that give differrent results to veterans vs. civis between old and young\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12233, DenseVector([0.3031, 0.5336, 0.6658, 0.2616, 0.2227, 0.272, 0.171, 0.0746]))\n",
      "(12244, DenseVector([0.3941, 0.5693, 0.6934, 0.4233, 0.2627, 0.2992, 0.2117, 0.0227]))\n",
      "(12255, DenseVector([0.4164, 0.642, 0.7501, 0.3946, 0.295, 0.3113, 0.2137, 0.0673]))\n",
      "(12266, DenseVector([0.2933, 0.5207, 0.6781, 0.3514, 0.2214, 0.2326, 0.1286, 0.0485]))\n"
     ]
    }
   ],
   "source": [
    "#vectors for comparing\n",
    "\n",
    "oldVetMean = (12233 , DenseVector([0.3031, 0.5336, 0.6658, 0.2616, 0.2227, 0.272, 0.17098, 0.07458]))\n",
    "print oldVetMean\n",
    "youngVetMean = (12244 , DenseVector([0.3941, 0.56934, 0.6934, 0.4233, 0.2627, 0.2992, 0.21167, 0.0227]))\n",
    "print youngVetMean\n",
    "oldCivMean = (12255 , DenseVector([0.4164, 0.642, 0.7501, 0.394645, 0.29499, 0.3113, 0.21368, 0.06731]))\n",
    "print oldCivMean\n",
    "youngCivMean = (12266 , DenseVector([0.2933, 0.52066, 0.6781, 0.35137, 0.2214, 0.2326, 0.1286, 0.04845]))\n",
    "print youngCivMean\n",
    "\n",
    "# youngVetMean = [0.3941, 0.56934, 0.6934, 0.4233, 0.2627, 0.2992, 0.21167, 0.0227]\n",
    "# oldCivMean = [0.4164, 0.642, 0.7501, 0.394645, 0.29499, 0.3113, 0.21368, 0.06731]\n",
    "# youngCivMean = [0.2933, 0.52066, 0.6781, 0.35137, 0.2214, 0.2326, 0.1286, 0.04845]\n",
    "# maxAll = [9,7,7,9,9,9,9,9]\n",
    "# minAll = [0,0,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = sc.parallelize([oldVetMean,youngVetMean,oldCivMean,youngCivMean])\n",
    "# print data2.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|            features|\n",
      "+-----+--------------------+\n",
      "|12233|[0.3031,0.5336,0....|\n",
      "|12244|[0.3941,0.56934,0...|\n",
      "|12255|[0.4164,0.642,0.7...|\n",
      "|12266|[0.2933,0.52066,0...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dr_df2 = ss.createDataFrame(data2, [\"id\",\"features\"])\n",
    "dr_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result2 = model.transform(dr_df2).select('id',\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|            features|\n",
      "+-----+--------------------+\n",
      "|73557|[0.0,0.0,0.0,0.0,...|\n",
      "|73558|[0.0,0.0,0.0,0.0,...|\n",
      "+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#dimensionality reduction\n",
    "\n",
    "[(73557, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])), (73558, DenseVector([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]))]\n",
    "\n",
    "# import pyspark.ml.feature\n",
    "from pyspark.ml.feature import PCA as PCA2\n",
    "from pyspark.ml.linalg import Vectors\n",
    "# from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "# data = [(Vectors.dense([2.0, 0.0, 3.0, 4.0, 5.0]),),\n",
    "#         (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),),\n",
    "#        (Vectors.dense([4.0, 0.0, 0.0, 6.0, 7.0]),)]\n",
    "# print data[0:2]\n",
    "# test = sc.parallelize(df_med_master.collect() + [oldVetMean,youngVetMean,oldCivMean,youngCivMean])\n",
    "# print  test.take(1)\n",
    "data = ss.createDataFrame(sc.parallelize(df_med_master.collect() + [oldVetMean,youngVetMean,oldCivMean,youngCivMean]), ['id', 'features'])\n",
    "print data.show(2)\n",
    "# dr_df = ss.createDataFrame(data, [\"id\",\"features\"])\n",
    "# # print 'alive'\n",
    "# dr_df.show(1)\n",
    "# pca = PCA2(k=3, inputCol=\"features\", outputCol=\"pcaFeatures\")\n",
    "\n",
    "\n",
    "# #---> troublesome code for PCA\n",
    "# model = pca.fit(dr_df)\n",
    "# print ' alive'\n",
    "# result = model.transform(dr_df).select('id',\"pcaFeatures\")\n",
    "# result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()\n",
    "ss.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous endeavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "# https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#random-forest-regression\n",
    "# https://spark.apache.org/docs/2.2.0/api/python/pyspark.ml.html#pyspark.ml.regression.RandomForestRegressor\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "\n",
    "def makingDenseVector(cleanLine): #this is only used for training\n",
    "    l = cleanLine\n",
    "    ID = int(l[0])  #this is the feature that we are testing for!!\n",
    "    features = l[1]\n",
    "    negOrPosPoint = [ID,Vectors.dense(features)]\n",
    "    return negOrPosPoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "testForForest  = ss.createDataFrame(vetDFOlder_Analyse_gS_df.rdd.map(list).map(lambda x: [x[0], list(x[1])]).map(makingDenseVector), [\"label\",\"features\"])\n",
    "print testForForest.show(2)\n",
    "rf = RandomForestRegressor(numTrees=2, maxDepth=2, seed=42)\n",
    "model = rf.fit(testForForest)\n",
    "print model.featureImportances\n",
    "\n",
    "\n",
    "# # test1 = ss.createDataFrame([(Vectors.sparse(-3.04,[float(0.11402268151574835)],[float(-2.4147302639021935)],))], [\"features\"])\n",
    "# # test1 = ss.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [\"features\"])\n",
    "# test1 = ss.createDataFrame([(Vectors.sparse(3,[float(0.11402268151574835)],[float(-2.4147302639021935)],))], [\"features\"])\n",
    "\n",
    "# model.transform(test1).head().prediction\n",
    "# # 0.5\n",
    "\n",
    "\n",
    "allclose(model.treeWeights, [1.0, 1.0])\n",
    "print model.transform(model).head().prediction\n",
    "model.numFeatures\n",
    "model.trees\n",
    "print dir(model)\n",
    "print \"\\n\"\n",
    "print model.treeWeights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# task 3\n",
    "\n",
    "#1 cluster based on demogs, then on exams, then cluster on both\n",
    "#2 take the top 3 participant profiles from each cluster defined by having the smallest disance (perhaps a centroid)\n",
    "#3 compare the mental health disorders of those top 3 per cluster\n",
    "#4 if they're similar we can determine that the cluster is some how grouping similar people.\n",
    "#5 from that we'll choose the most comparable 2 clusters btw vet and civ in order to tell if there are any differences.\n",
    "#6 Thereby allowing us to make possible suggestions to vetts based off of their similar civ counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering (testing mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import KMeans, KMeansModel\n",
    "from math import sqrt\n",
    "# testrdd = civiDFyounger_clean_normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "labeledRdd = civiDFyounger_clean_normalized_list.map(lambda x: (x[0], np.array(x[1:]))).cache()\n",
    "\n",
    "featureRdd = civiDFyounger_clean_normalized_list.map(lambda x:  np.array(x[1:])).cache()\n",
    "\n",
    "featureData = nonlabeledRdd\n",
    "\n",
    "print civiDFyounger_clean_normalized_list.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print featureRdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(point):\n",
    "        center = clusters.centers[clusters.predict(point)]\n",
    "        return sqrt(sum([x**2 for x in (point - center)]))\n",
    "\n",
    "ks = []\n",
    "es = []\n",
    "for k in  [1,2,3,4,5,6,7,10,20]:\n",
    "    clusters = KMeans.train(featureRdd, k, maxIterations=10, initializationMode=\"random\")\n",
    "    WSSSE = featureRdd.map(lambda point: error(point)).reduce(lambda x, y: x + y)\n",
    "    ks.append(k)\n",
    "    es.append(WSSSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ks,es)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans.train(featureRdd, 6, maxIterations=10, initializationMode=\"random\")\n",
    "print clusters.clusterCenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print myrdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print clusters.predict( np.array([0.        , 0.        , 0.33333333, 0.11111111, 0.        , 0.        , 0.        , 0.        ] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = labeledRdd.map( lambda kv: (clusters.predict( kv[1]) , kv[0]) )\n",
    "print predictions.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in predictions.groupByKey().collect():\n",
    "    print \"\\nNew cluster:\", clusters.centers[e[0]]\n",
    "    print [v for v in e[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clusters.fit(featureData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters = KMeans().setK(2).setSeed(1)\n",
    "# model = kmeans.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark.ml.clustering",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f2fb84acddf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Loads data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataset = spark.read.format(\"libsvm\").load(\"data/mllib/sample_kmeans_data.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pyspark.ml.clustering"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "# Loads data.\n",
    "# dataset = spark.read.format(\"libsvm\").load(\"data/mllib/sample_kmeans_data.txt\")\n",
    "\n",
    "# Trains a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(dataset)\n",
    "\n",
    "# Evaluate clustering by computing Within Set Sum of Squared Errors.\n",
    "wssse = model.computeCost(dataset)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "# Shows the result.\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# civiDFyounger_clean_normalized_list = civiDFyounger_clean_normalized.rdd.map(list)\n",
    "# print civiDFyounger_clean_normalized_list.take(1)\n",
    "\n",
    "# civiDFyounger_clean_normalized_list_Labled = civiDFyounger_clean_normalized_list.map(lambda x: (x[0], x[1:])).cache()\n",
    "# print civiDFyounger_clean_normalized_list_Labled.take(2)\n",
    "\n",
    "# cSchema = StructType([StructField(\"WordList\", ArrayType(StringType()))])\n",
    "\n",
    "# import random\n",
    "# print len(testteset)\n",
    "# listSizeReduction = random.sample(testteset, 100)\n",
    "# print listSizeReduction[0]\n",
    "# print len(listSizeReduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def turingToArray(rdd):\n",
    "#     d = line.split(\",\")\n",
    "#     key = d[0]\n",
    "#     value = d[1:]\n",
    "#     value = np.array([float(v) for v in value])\n",
    "\n",
    "#scratch\n",
    "#mymyrdd =  sc.parallelize(myrdd.take(7))\n",
    "# df.fillna(0)\n",
    "# print mymyrdd.take(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following was an attempt to merge all of the file into one big file called df\n",
    "#it worked, but it ran too slowly\n",
    "\n",
    "# df = df2.join(df3) #.join(df4)#.join(df4).join(df5).join(df6)\n",
    "# df = df3.join(df1, [ \"SEQN\" ]).join(df2, [ \"SEQN\" ])\\\n",
    "#         .join(df4, [ \"SEQN\" ]).join(df6, [ \"SEQN\" ])\n",
    "'''\n",
    "    #not using medication becaus it has multiples of same\n",
    "''' \n",
    "# newThing = df4.join(df5, [ \"SEQN\" ])#.join(df5, [ \"SEQN\" ])\n",
    "\n",
    "# df.join([df3,df1], join='SEQN')\n",
    "# join(other, on=None, how=None)\n",
    "\n",
    "# df = df.dropDuplicates(subset=None)\n",
    "# print df.count()\n",
    "# df.createGlobalTempView(\"merging\")\n",
    "# df.show(n=1, truncate=True) #it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting to turn the RDD into a Datafile instead of just importing the CSV as a dataframe\n",
    "\n",
    "# examinationRDD.take(3)\n",
    "# examinationList = open(\"/scratch/ISE495/2018_project_02/NHANES/examination.csv\").readlines()# print examinationList[0]\n",
    "# columnNames = examinationList[0].replace('\"',\"\").split(\",\")\n",
    "# print columnNames[0:20]\n",
    "# numCols = len(columnNames)\n",
    "\n",
    "# print len(examinationList[1].split(','))\n",
    "# data4types = examinationList[2].split(\",\")\n",
    "# print data4types[:]\n",
    "# # print type(dataTypes[0])x\n",
    "\n",
    "# print len(data4types)\n",
    "\n",
    "# stringTest = \"ima string\"\n",
    "# intTest = 2\n",
    "# floatTest = 4.0\n",
    "# colDataTypes = []\n",
    "# for x in data4types:\n",
    "##     print type(x)\n",
    "#     if type(x) == type(4634.21):\n",
    "#         colDataTypes.append(\"FloatType()\")\n",
    "#     elif type(x) == type(2):\n",
    "#         colDataTypes.append(\"IntegerType()\")\n",
    "#     elif type(x) == type(\"ima string\"):\n",
    "#         colDataTypes.append(\"StringType()\")\n",
    "\n",
    "# print colDataTypes\n",
    "# print len(colDataTypes)\n",
    "# print dataTypes\n",
    "\n",
    "# from pyspark.sql.types import *\n",
    "\n",
    "# fields = [StructField(\"cuisineName\", StringType(), True),\n",
    "#          StructField(\"recipeID\", IntegerType(), False),\n",
    "#          StructField(\"ingredient\", StringType(), True)]\n",
    "# schema = StructType(fields)\n",
    "\n",
    "# print schema\n",
    "# print type(schema)\n",
    "\n",
    "# recipeDF2 = ss.createDataFrame(recipesRDD, schema)\n",
    "# print recipeDF2.show()\n",
    "# print \"\\n\\n\"\n",
    "# print type(recipeDF2)\n",
    "\n",
    "'''\n",
    "# Implicit DF creation\n",
    "# Step-1: Think how to deal with first row.\n",
    "# Step-2: The following kind of statement.\n",
    "recipeRows = recipesRDD.map(lambda line: Row(cuisineName=line[0],\\\n",
    "                                            recipeID=line[1],\\\n",
    "                                            ingredient=line[2]),\\\n",
    "                                            col3=val[3],\\\n",
    "                                           col4=val[4],\\\n",
    "                                           col5=val[5],\\\n",
    "                                           .......)\n",
    "# Step-3: Create a DF from Rows data\n",
    "'''\n",
    "\n",
    "# l = examinationList[1].split(\",\")\n",
    "# print l\n",
    "# print len(l)\n",
    "\n",
    "# #l = [\"suresh\", 5, 5.67]\n",
    "# types = []\n",
    "# for i in range(224):\n",
    "#     types.append(type(l[i]))\n",
    "# print types\n",
    "\n",
    "#typeKeys = []\n",
    "#for i in range(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
